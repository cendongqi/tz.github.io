<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小歪的博客</title>
  <subtitle>人生苦短，我学Python</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zhangslob.github.io/"/>
  <updated>2018-07-17T13:47:14.505Z</updated>
  <id>https://zhangslob.github.io/</id>
  
  <author>
    <name>小歪</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用Selenium与Requests模拟登陆</title>
    <link href="https://zhangslob.github.io/2018/07/17/%E4%BD%BF%E7%94%A8Selenium%E4%B8%8ERequests%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86/"/>
    <id>https://zhangslob.github.io/2018/07/17/使用Selenium与Requests模拟登陆/</id>
    <published>2018-07-17T13:18:35.000Z</published>
    <updated>2018-07-17T13:47:14.505Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://preview.ibb.co/cd5VUJ/20180717173128.png" alt=""></p>
<pre><code>这是崔斯特的第五十九篇原创文章
</code></pre><p>模拟登陆的两种方式，你喜欢哪种  (๑• . •๑)</p>
<a id="more"></a>
<p>本期讲一讲模拟登录相关的东西，目标网站是<a href="https://github.com/" target="_blank" rel="external">Github</a></p>
<p><img src="https://preview.ibb.co/cd5VUJ/20180717173128.png" alt=""></p>
<h1 id="简单的Selnium"><a href="#简单的Selnium" class="headerlink" title="简单的Selnium"></a>简单的Selnium</h1><p>想说说简单的方法，使用浏览器登录，基本上就是傻瓜操作了。</p>
<p>如上图所示，登录设计的很简单，没有验证码什么的，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</div><div class="line"></div><div class="line">driver = webdriver.Chrome()</div><div class="line">driver.maximize_window()</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">(account, password)</span>:</span></div><div class="line">    driver.get(<span class="string">'https://github.com/login'</span>)</div><div class="line">    time.sleep(<span class="number">2</span>)</div><div class="line">    driver.find_element_by_id(<span class="string">'login_field'</span>).send_keys(account)</div><div class="line">    driver.find_element_by_id(<span class="string">'password'</span>).send_keys(password)</div><div class="line">    driver.find_element_by_xpath(<span class="string">'//input[@class="btn btn-primary btn-block"]'</span>).click()</div><div class="line">    <span class="comment"># do whatever you want</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    account, password = <span class="string">'account'</span>, <span class="string">'password'</span></div><div class="line">    login(account, password)</div></pre></td></tr></table></figure>
<h1 id="分析请求之Requests"><a href="#分析请求之Requests" class="headerlink" title="分析请求之Requests"></a>分析请求之Requests</h1><p>打开F12，使用错误的账号密码登录，复制curl</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl <span class="string">'https://github.com/session'</span> -H <span class="string">'Cookie: has_recent_activity=1; _octo=GH1.1.1477592343.1531820067; logged_in=no; _gh_sess=UEZzYnVCMVlhNkVOdE5rU1hWRFpDbmFlY0UyQ1Y2b3Z4TGw2NFlTMmJLUWk5VENVQ3Q4TWxiSWN5ckEyZXN0MUFkT29XVjQvbWJVbm9RV0JNQmc1TmU0UnBtK0taUXJpcElqUk5PNGZ5TjZOQ2ZPRVR4NU5WQXcrb2xWRnRBMnRPMkRWYzYvWmVGY0FrYU12Q3BVVTY3dXVSblliNG4rWjc2QXVwR2pjQ1pzZXM1MFk1MjU5OUw2WkFLTU1BMzJDWGlTeXliNzNaejlUaW43cWhFNzQ0MFFVVmJ1aEppbzdtQTZkRERmUm5mWExkRDlmWW5lNk9mdlFYb05MQUtubDZBbXFJWjV6eFhic3JiWlRtZ2QxZ2FqZUxnOGFheUgzaXJmc290b0Jma09pRTJZdHZySEVmdVdGZHVBU3ZTVTJRM0pESnE1N1VPRDM0ck9FZzNJZTN5VWljUktyZ3FZQU16THVBeFBXV3BNPS0tSDh4WVV6U2RSNjlBL3FNQ3VaRGxEUT09--71cf0886128d55b42c82cf6f7b76e007ebfdc77b; _ga=GA1.2.57857743.1531820085; _gat=1; tz=Asia%2FShanghai'</span> -H <span class="string">'Origin: https://github.com'</span> -H <span class="string">'Accept-Encoding: gzip, deflate, br'</span> -H <span class="string">'Accept-Language: zh-CN,zh;q=0.9,en;q=0.8'</span> -H <span class="string">'Upgrade-Insecure-Requests: 1'</span> -H <span class="string">'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'</span> -H <span class="string">'Content-Type: application/x-www-form-urlencoded'</span> -H <span class="string">'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span> -H <span class="string">'Cache-Control: max-age=0'</span> -H <span class="string">'Referer: https://github.com/login'</span> -H <span class="string">'Connection: keep-alive'</span> --data <span class="string">'commit=Sign+in&amp;utf8=%E2%9C%93&amp;authenticity_token=%2BtgUHwMIxnoHOHNMqQFkLak9mJzrxt%2B4yfFiZaf66WiMB5ZyRaVXq%2BFpZsM%2BtxgaRRX6Fzfezu1IdRqy%2BTGHwg%3D%3D&amp;login=123456788%40gmail.com&amp;password=123456788'</span> --compressed</div></pre></td></tr></table></figure>
<p>转为Python代码，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line">cookies = &#123;</div><div class="line">    <span class="string">'has_recent_activity'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'_octo'</span>: <span class="string">'GH1.1.1477592343.1531820067'</span>,</div><div class="line">    <span class="string">'logged_in'</span>: <span class="string">'no'</span>,</div><div class="line">    <span class="string">'_gh_sess'</span>: <span class="string">'UEZzYnVCMVlhNkVOdE5rU1hWRFpDbmFlY0UyQ1Y2b3Z4TGw2NFlTMmJLUWk5VENVQ3Q4TWxiSWN5ckEyZXN0MUFkT29XVjQvbWJVbm9RV0JNQmc1TmU0UnBtK0taUXJpcElqUk5PNGZ5TjZOQ2ZPRVR4NU5WQXcrb2xWRnRBMnRPMkRWYzYvWmVGY0FrYU12Q3BVVTY3dXVSblliNG4rWjc2QXVwR2pjQ1pzZXM1MFk1MjU5OUw2WkFLTU1BMzJDWGlTeXliNzNaejlUaW43cWhFNzQ0MFFVVmJ1aEppbzdtQTZkRERmUm5mWExkRDlmWW5lNk9mdlFYb05MQUtubDZBbXFJWjV6eFhic3JiWlRtZ2QxZ2FqZUxnOGFheUgzaXJmc290b0Jma09pRTJZdHZySEVmdVdGZHVBU3ZTVTJRM0pESnE1N1VPRDM0ck9FZzNJZTN5VWljUktyZ3FZQU16THVBeFBXV3BNPS0tSDh4WVV6U2RSNjlBL3FNQ3VaRGxEUT09--71cf0886128d55b42c82cf6f7b76e007ebfdc77b'</span>,</div><div class="line">    <span class="string">'_ga'</span>: <span class="string">'GA1.2.57857743.1531820085'</span>,</div><div class="line">    <span class="string">'_gat'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'tz'</span>: <span class="string">'Asia%2FShanghai'</span>,</div><div class="line">&#125;</div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'Origin'</span>: <span class="string">'https://github.com'</span>,</div><div class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</div><div class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.9,en;q=0.8'</span>,</div><div class="line">    <span class="string">'Upgrade-Insecure-Requests'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'</span>,</div><div class="line">    <span class="string">'Content-Type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</div><div class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span>,</div><div class="line">    <span class="string">'Cache-Control'</span>: <span class="string">'max-age=0'</span>,</div><div class="line">    <span class="string">'Referer'</span>: <span class="string">'https://github.com/login'</span>,</div><div class="line">    <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</div><div class="line">&#125;</div><div class="line"></div><div class="line">data = [</div><div class="line">  (<span class="string">'commit'</span>, <span class="string">'Sign in'</span>),</div><div class="line">  (<span class="string">'utf8'</span>, <span class="string">'\u2713'</span>),</div><div class="line">  (<span class="string">'authenticity_token'</span>, <span class="string">'+tgUHwMIxnoHOHNMqQFkLak9mJzrxt+4yfFiZaf66WiMB5ZyRaVXq+FpZsM+txgaRRX6Fzfezu1IdRqy+TGHwg=='</span>),</div><div class="line">  (<span class="string">'login'</span>, <span class="string">'123456788@gmail.com'</span>),</div><div class="line">  (<span class="string">'password'</span>, <span class="string">'123456788'</span>),</div><div class="line">]</div><div class="line"></div><div class="line">response = requests.post(<span class="string">'https://github.com/session'</span>, headers=headers, cookies=cookies, data=data)</div></pre></td></tr></table></figure>
<p>注意两个地方，cookies和参数，先来看看参数，稍微特别的就是<code>authenticity_token</code>，感觉是验证。<code>Ctrl+Shift+F</code>打开搜索，最终在返回的html中找到</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment">&lt;!-- '"` --&gt;</span><span class="comment">&lt;!-- &lt;/textarea&gt;&lt;/xmp&gt; --&gt;</span><span class="tag">&lt;/<span class="name">option</span>&gt;</span><span class="tag">&lt;/<span class="name">form</span>&gt;</span><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/session"</span> <span class="attr">accept-charset</span>=<span class="string">"UTF-8"</span> <span class="attr">method</span>=<span class="string">"post"</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">"utf8"</span> <span class="attr">type</span>=<span class="string">"hidden"</span> <span class="attr">value</span>=<span class="string">"&amp;#x2713;"</span> /&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"hidden"</span> <span class="attr">name</span>=<span class="string">"authenticity_token"</span> <span class="attr">value</span>=<span class="string">"CTujn/pHGMQBpEhYcJj9Mn6ChsNSkd5ul8rgNSP/6/KxdZlhS0ABKblsq1pLn6EaQvIGLMzl/IQawaDL8KFjDw=="</span> /&gt;</span>      <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"auth-form-header p-0"</span>&gt;</span></div></pre></td></tr></table></figure>
<p><code>authenticity_token</code>解决了，下一步想办法获取cookies</p>
<p><img src="https://preview.ibb.co/iSWqwy/20180717174236.png" alt=""></p>
<p>继续搜索<code>_gh_sess</code>与<code>_octo</code>关键字，看到有这样一段js</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> e, t = <span class="keyword">void</span> <span class="number">0</span>, r = <span class="keyword">void</span> <span class="number">0</span>, n = <span class="keyword">this</span>._getCookie(<span class="string">"_octo"</span>), a = [];</div></pre></td></tr></table></figure>
<p>猜测cookies不是本地生成，查看打开Github首页的请求，果然在<code>Response Cookies</code>中找到了相关数据，那么使用<code>Session</code>就可以维持会话了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span>,</div><div class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</div><div class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.9,en;q=0.8'</span>,</div><div class="line">    <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</div><div class="line">    <span class="string">'Host'</span>: <span class="string">'github.com'</span>,</div><div class="line">    <span class="string">'Upgrade-Insecure-Requests'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">s = requests.session()</div><div class="line">s.headers.update(headers)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_token</span><span class="params">()</span>:</span></div><div class="line">    url = <span class="string">'https://github.com/login'</span></div><div class="line">    response = s.get(url)</div><div class="line">    pat = <span class="string">'name=\"authenticity_token\" value=\"(.*?)\"'</span></div><div class="line">    authenticity_token = re.findall(pat, response.text)[<span class="number">0</span>]</div><div class="line">    <span class="keyword">return</span> authenticity_token</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">(authenticity_token, account, password)</span>:</span></div><div class="line">    payload = &#123;</div><div class="line">        <span class="string">'commit'</span>: <span class="string">'Sign in'</span>,</div><div class="line">        <span class="string">'utf8'</span>: <span class="string">'\u2713'</span>,</div><div class="line">        <span class="string">'authenticity_token'</span>: authenticity_token,</div><div class="line">        <span class="string">'login'</span>: account,</div><div class="line">        <span class="string">'password'</span>: password,</div><div class="line">    &#125;</div><div class="line">    url = <span class="string">'https://github.com/session'</span></div><div class="line">    response = s.post(url, data=payload)</div><div class="line">    print(response)</div><div class="line">    <span class="comment"># do whatever you want</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    account, password = <span class="string">'account'</span>, <span class="string">'password'</span></div><div class="line">    authenticity_token = get_token()</div><div class="line">    login(authenticity_token, account, password)</div></pre></td></tr></table></figure>
<h1 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h1><p>Selenium：</p>
<ul>
<li>优点：简单、无脑，不用分析复杂的网页请求，不用保持会话状态</li>
<li>缺点：速度慢，速度慢，速度慢（某些情况下会出现js加载不全）</li>
</ul>
<p><img src="http://www.goalsinfocloud.com/wp-content/uploads/2018/02/selenium.png" alt=""></p>
<p>Requests：</p>
<ul>
<li>优点：速度快，可以增加自己对cookies登陆的理解</li>
<li>缺点：需要花时间寻找相关参数</li>
</ul>
<p><img src="http://docs.python-requests.org/en/master/_static/requests-sidebar.png" alt=""></p>
<p>如果对Github感兴趣，可以直接使用 <a href="https://developer.github.com/v3/" target="_blank" rel="external">Github API</a></p>
<p>最近在使用<code>Selenium</code>处理验证码，发现很强大，如果模拟请求，难度会非常大。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://preview.ibb.co/cd5VUJ/20180717173128.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;这是崔斯特的第五十九篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;模拟登陆的两种方式，你喜欢哪种  (๑• . •๑)&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Selenium" scheme="https://zhangslob.github.io/tags/Selenium/"/>
    
      <category term="Requests" scheme="https://zhangslob.github.io/tags/Requests/"/>
    
  </entry>
  
  <entry>
    <title>说说最近遇到的反爬</title>
    <link href="https://zhangslob.github.io/2018/07/10/%E8%AF%B4%E8%AF%B4%E6%9C%80%E8%BF%91%E9%81%87%E5%88%B0%E7%9A%84%E5%8F%8D%E7%88%AC/"/>
    <id>https://zhangslob.github.io/2018/07/10/说说最近遇到的反爬/</id>
    <published>2018-07-10T15:07:44.000Z</published>
    <updated>2018-07-10T15:13:23.022Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十八篇原创文章
</code></pre><p>爬虫与反爬  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/qb1MMqd.jpg" alt=""></p>
<a id="more"></a>
<h1 id="参数加密"><a href="#参数加密" class="headerlink" title="参数加密"></a>参数加密</h1><p>参数加密指的是在请求中需要加上类似<code>token</code>、<code>uuid</code> 字段，例如在某个请求中<code>query string parameters</code>中有<code>_token</code>和<code>uuid</code>、<code>customerKey</code>等字段，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">_token:eJyN0l9L40AQAPDvsg8+hWZ2</div><div class="line">uuid:59851b5e-92b4<span class="_">-f</span>1f5-19e2<span class="_">-d</span>8148bf7e</div><div class="line">customerKey:0356982437</div></pre></td></tr></table></figure>
<p><strong>解决方法</strong></p>
<p>刚开始遇到这个是一脸懵逼的，验证发现有些参数不是必须的，比如<code>uuid</code>，<code>uuid</code>在维基百科上是：通用唯一识别码，估计没啥作用，python也有内置的uuid生成库 <a href="https://docs.python.org/3/library/uuid.html" target="_blank" rel="external">uuid — UUID objects according to RFC 4122</a></p>
<p>问了前端大佬，得知需要在js中打断点，一点点调试，最后终于解决，<code>_token</code>是二次加密的。</p>
<p>给大家看一下该网站的部分代码。看看描述：<strong>获得反爬虫的_toke</strong></p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * 获得反爬虫的_token</div><div class="line"> * @param &#123;*&#125; url </div><div class="line"> * @param &#123;*&#125; queryParams </div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">getRohrToken</span>(<span class="params">host, queryParams</span>) </span>&#123;</div><div class="line">    <span class="keyword">if</span> (<span class="built_in">window</span>.Rohr_Opt &amp;&amp; <span class="built_in">window</span>.Rohr_Opt.reload) &#123;</div><div class="line">        <span class="keyword">var</span> rohr = <span class="built_in">window</span>.Rohr_Opt;</div><div class="line"></div><div class="line">        <span class="keyword">var</span> _token = <span class="string">''</span>;</div><div class="line">        <span class="keyword">var</span> params = queryParams</div><div class="line">        <span class="keyword">if</span> (<span class="keyword">typeof</span> params == <span class="string">'string'</span> &amp;&amp; params.indexOf(<span class="string">'_fb_='</span>) !== <span class="number">-1</span>) &#123;</div><div class="line">            params = <span class="string">''</span></div><div class="line">        &#125;</div><div class="line">        <span class="keyword">var</span> queryString = toQueryString(params);</div><div class="line"></div><div class="line">        <span class="keyword">var</span> _url = location.protocol + host + <span class="string">'?'</span> + queryString;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            _token = rohr.reload(_url) || <span class="string">''</span>;</div><div class="line">        &#125; <span class="keyword">catch</span> (e) &#123;</div><div class="line">            <span class="built_in">console</span>.log(<span class="string">'获取token失败:'</span> + e)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> _token;</div><div class="line">    &#125;;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>关于如何调试，这里有教程，<a href="http://wiki.jikexueyuan.com/project/chrome-devtools/debugging-javascript.html" target="_blank" rel="external">调试 JavaScript 脚本</a> </p>
<blockquote>
<p>这里还有另一种app抓包加密情况，暂时还没接触过，听过是需要反编译apk包，然后阅读代码。</p>
</blockquote>
<h1 id="登录问题"><a href="#登录问题" class="headerlink" title="登录问题"></a>登录问题</h1><p>很多网站数据是登录可见，那么就必须要开发该网站的登录系统了。</p>
<p>登录可能会遇到的一些问题：</p>
<ol>
<li>登录过程中遇到的验证码（下面会说）</li>
<li>cookies持久化问题</li>
<li>账号被封禁问题</li>
</ol>
<p><strong>解决方法</strong></p>
<ul>
<li><p>登录账号获得<code>cookies</code>后，经过一段时间，<code>cookies</code>就可能会失效，具体网站情况不同，这时候就必须有个脚本，来保证<code>cookies</code>有效</p>
</li>
<li><p>账号做出一些跟正常用户不同的操作就会产生异常，别人很容易就发现。所以就让你的账号像正常人一样。</p>
</li>
</ul>
<p>最近看到有人再问豆瓣登录采集影评导致被封号的事情，豆瓣我以前也被封过，到现在也没有解封</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">依据用户管理细则，此帐号已被永久停用。停用时间:2017-09-29</div><div class="line">如有疑问，请发送邮件到<span class="built_in">help</span>@douban.com</div></pre></td></tr></table></figure>
<p>我的建议是：</p>
<ol>
<li>有能力的多注册账号，账号被封了就再去注册呗</li>
<li>手机app抓包，app不需要登录，而且可以持续抓最新评论</li>
</ol>
<h1 id="图形验证码"><a href="#图形验证码" class="headerlink" title="图形验证码"></a>图形验证码</h1><p>验证码一直是反爬虫利器，从简单的数字识别，到复杂的滑动拼图、图片点选等等。有兴趣的来试试破解 <a href="http://dun.163.com/trial/picture-click" target="_blank" rel="external">网易云易盾</a>，感觉很头疼。</p>
<p><img src="https://image.ibb.co/ebAMMo/20180710202053.png" alt=""></p>
<p><strong>解决方法</strong></p>
<p>例如上图，这是我现在遇到的一种验证码情况，依次点击几个文字。</p>
<p>如果是自己来做的话，会考虑这样：</p>
<ol>
<li>将验证码图片部分截图或下载回来</li>
<li>对图片进行OCR，提取文字</li>
<li>文字识别，获取坐标</li>
<li>使用<code>selenium</code>根据坐标点击</li>
</ol>
<p>这只是初步思路，但想法很容易，做起来却没那么简单。</p>
<p>在Github上找到大佬写的方法 <a href="https://github.com/cos120/captcha_crack" target="_blank" rel="external">captcha_crack</a>，知乎上也有 <a href="https://zhuanlan.zhihu.com/p/34186397" target="_blank" rel="external">使用深度学习破解点击验证码</a></p>
<p>那么如果直接接入第三方打码平台来，那就会简单很多，在实际开发中为了提高准确性，更多会使用打码平台。</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十八篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;爬虫与反爬  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/qb1MMqd.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="反爬" scheme="https://zhangslob.github.io/tags/%E5%8F%8D%E7%88%AC/"/>
    
  </entry>
  
  <entry>
    <title>快速写一个爬虫</title>
    <link href="https://zhangslob.github.io/2018/07/03/%E5%BF%AB%E9%80%9F%E5%86%99%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB/"/>
    <id>https://zhangslob.github.io/2018/07/03/快速写一个爬虫/</id>
    <published>2018-07-03T14:55:51.718Z</published>
    <updated>2018-07-03T15:20:52.732Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十七篇原创文章
</code></pre><p>快、更快  (๑• . •๑)</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1530640088638&amp;di=367da0e00206dae5988d7515df52c2a9&amp;imgtype=jpg&amp;src=http%3A%2F%2Fimg1.imgtn.bdimg.com%2Fit%2Fu%3D1476255146%2C3695215484%26fm%3D214%26gp%3D0.jpg" alt=""></p>
<a id="more"></a>
<h1 id="缘来"><a href="#缘来" class="headerlink" title="缘来"></a>缘来</h1><p>今天下班前，老板让我帮忙爬一个数据，简单看了下，需要登录，看起来应该不难。回到家，注册一个账号，复制<code>url</code>，然后用postman转代码，简单暴力，直接撸。</p>
<blockquote>
<p>这里说下postman的一个BUG，发送请求不会获得任何数据，如果你遇到，建议升级postman为最新版本</p>
</blockquote>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> pymongo</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> traceback</div><div class="line"><span class="keyword">from</span> concurrent <span class="keyword">import</span> futures</div><div class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urljoin</div><div class="line"><span class="keyword">from</span> scrapy.selector <span class="keyword">import</span> Selector</div><div class="line"></div><div class="line"></div><div class="line">logging.basicConfig(level=logging.INFO)</div><div class="line"></div><div class="line">client = pymongo.MongoClient()</div><div class="line">coll = client[<span class="string">'table'</span>][<span class="string">'collection'</span>]</div><div class="line"><span class="comment"># coll.create_index('url', unique=True)</span></div><div class="line"></div><div class="line">url = <span class="string">"your urls"</span></div><div class="line"></div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'user-agent'</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 "</span></div><div class="line">                  <span class="string">"(KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36"</span>,</div><div class="line">    <span class="string">'accept'</span>: <span class="string">"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8"</span>,</div><div class="line">    <span class="string">'accept-encoding'</span>: <span class="string">"gzip, deflate, br"</span>,</div><div class="line">    <span class="string">'accept-language'</span>: <span class="string">"zh-CN,zh;q=0.9,en;q=0.8"</span>,</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(page)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        proxies = &#123;</div><div class="line">            <span class="string">'http'</span>: proxy,</div><div class="line">            <span class="string">'https'</span>: proxy</div><div class="line">        &#125;</div><div class="line">        response = requests.get(url.format(page), headers=headers, timeout=<span class="number">20</span>, proxies=proxies)</div><div class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</div><div class="line">            s = Selector(text=response.text)</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> s.xpath(<span class="string">'//*[@id="search-results"]/tbody/tr'</span>):</div><div class="line">                url_ = i.xpath(<span class="string">'td[4]/a/@href'</span>).extract_first()</div><div class="line">                detail_url = urljoin(url, url_)</div><div class="line">                data = get_detail(detail_url)</div><div class="line">                logging.info(<span class="string">'success save data &#123;&#125; '</span>.format(data[<span class="string">'url'</span>]))</div><div class="line">                save_mongo(data)</div><div class="line"></div><div class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">        logging.error(traceback.format_exc())</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_detail</span><span class="params">(detail_url)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        proxies = &#123;</div><div class="line">            <span class="string">'http'</span>: proxy,</div><div class="line">            <span class="string">'https'</span>: proxy</div><div class="line">        &#125;</div><div class="line">        response = requests.get(detail_url, headers=headers, timeout=<span class="number">20</span>, proxies=proxies)</div><div class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</div><div class="line">            s = Selector(text=response.text)</div><div class="line">            data = dict()</div><div class="line">            data[<span class="string">'url'</span>] = detail_url</div><div class="line">            data[<span class="string">'SMILES '</span>] = s.xpath(<span class="string">'//*[@id="smiles"]/text()'</span>).extract_first()</div><div class="line">            img = s.xpath(<span class="string">'//*[@id="molecule-image"]/img/@src'</span>).extract_first()</div><div class="line">            data[<span class="string">'img'</span>] = urljoin(detail_url, img)</div><div class="line">            data[<span class="string">'formula'</span>] = s.xpath(<span class="string">'//*[@id="name-structure"]/tbody/tr[2]/td[2]/text()'</span>).extract_first()</div><div class="line">            data[<span class="string">'Mass'</span>] = s.xpath(<span class="string">'//*[@id="name-structure"]/tbody/tr[3]/td[2]/text()'</span>).extract_first()</div><div class="line"></div><div class="line">            <span class="keyword">return</span> data</div><div class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">        logging.error(traceback.format_exc())</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_mongo</span><span class="params">(data)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        coll.insert(data)</div><div class="line">    <span class="keyword">except</span> pymongo.errors.DuplicateKeyError:</div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="comment"># for i in range(1, 11):</span></div><div class="line">    <span class="comment">#     fetch(str(i))</span></div><div class="line"></div><div class="line">    <span class="comment"># if use Thread</span></div><div class="line">    <span class="keyword">with</span> futures.ThreadPoolExecutor(max_workers=<span class="number">50</span>) <span class="keyword">as</span> executor:</div><div class="line">            to_do = []</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">51</span>):</div><div class="line">                future = executor.submit(fetch, str(i))</div><div class="line">                to_do.append(future)</div></pre></td></tr></table></figure>
<p>代码相当简单，<code>fetch</code>函数用来抓取列表页，<code>get_detail</code>函数抓取详情页，<code>save_mongo</code>保存数据库，需要说明下的就是最后使用的多线程了，这里号使用的是<code>futures</code>，并不想说很多大道理，来看看<a href="https://docs.python.org/3/library/concurrent.futures.html" target="_blank" rel="external">文档</a></p>
<h1 id="提高速度"><a href="#提高速度" class="headerlink" title="提高速度"></a>提高速度</h1><p>concurrent.futures 是python3新增加的一个库，用于并发处理，提供了多线程和多进程的并发功能 </p>
<p><strong>线程池</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> concurrent.futures</div><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line"></div><div class="line">URLS = [<span class="string">'http://www.foxnews.com/'</span>,</div><div class="line">        <span class="string">'http://www.cnn.com/'</span>,</div><div class="line">        <span class="string">'http://europe.wsj.com/'</span>,</div><div class="line">        <span class="string">'http://www.bbc.co.uk/'</span>,</div><div class="line">        <span class="string">'http://some-made-up-domain.com/'</span>]</div><div class="line"></div><div class="line"><span class="comment"># Retrieve a single page and report the URL and contents</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_url</span><span class="params">(url, timeout)</span>:</span></div><div class="line">    <span class="keyword">with</span> urllib.request.urlopen(url, timeout=timeout) <span class="keyword">as</span> conn:</div><div class="line">        <span class="keyword">return</span> conn.read()</div><div class="line"></div><div class="line"><span class="comment"># We can use a with statement to ensure threads are cleaned up promptly</span></div><div class="line"><span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor(max_workers=<span class="number">5</span>) <span class="keyword">as</span> executor:</div><div class="line">    <span class="comment"># Start the load operations and mark each future with its URL</span></div><div class="line">    future_to_url = &#123;executor.submit(load_url, url, <span class="number">60</span>): url <span class="keyword">for</span> url <span class="keyword">in</span> URLS&#125;</div><div class="line">    <span class="keyword">for</span> future <span class="keyword">in</span> concurrent.futures.as_completed(future_to_url):</div><div class="line">        url = future_to_url[future]</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            data = future.result()</div><div class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> exc:</div><div class="line">            print(<span class="string">'%r generated an exception: %s'</span> % (url, exc))</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            print(<span class="string">'%r page is %d bytes'</span> % (url, len(data)))</div></pre></td></tr></table></figure>
<p><strong>进程池</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> concurrent.futures</div><div class="line"><span class="keyword">import</span> math</div><div class="line"></div><div class="line">PRIMES = [</div><div class="line">    <span class="number">112272535095293</span>,</div><div class="line">    <span class="number">112582705942171</span>,</div><div class="line">    <span class="number">112272535095293</span>,</div><div class="line">    <span class="number">115280095190773</span>,</div><div class="line">    <span class="number">115797848077099</span>,</div><div class="line">    <span class="number">1099726899285419</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_prime</span><span class="params">(n)</span>:</span></div><div class="line">    <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line"></div><div class="line">    sqrt_n = int(math.floor(math.sqrt(n)))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>, sqrt_n + <span class="number">1</span>, <span class="number">2</span>):</div><div class="line">        <span class="keyword">if</span> n % i == <span class="number">0</span>:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">True</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor() <span class="keyword">as</span> executor:</div><div class="line">        <span class="keyword">for</span> number, prime <span class="keyword">in</span> zip(PRIMES, executor.map(is_prime, PRIMES)):</div><div class="line">            print(<span class="string">'%d is prime: %s'</span> % (number, prime))</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>
<p>关于入库方面，建议是增加唯一索引， <code>coll.create_index(&#39;url&#39;, unique=True)</code>，一个是去重，一个是提高查询速度。</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十七篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;快、更快  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://timgsa.baidu.com/timg?image&amp;amp;quality=80&amp;amp;size=b9999_10000&amp;amp;sec=1530640088638&amp;amp;di=367da0e00206dae5988d7515df52c2a9&amp;amp;imgtype=jpg&amp;amp;src=http%3A%2F%2Fimg1.imgtn.bdimg.com%2Fit%2Fu%3D1476255146%2C3695215484%26fm%3D214%26gp%3D0.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>Katalon + 傻瓜 == selenium</title>
    <link href="https://zhangslob.github.io/2018/06/25/Katalon-selenium-%E5%82%BB%E7%93%9C/"/>
    <id>https://zhangslob.github.io/2018/06/25/Katalon-selenium-傻瓜/</id>
    <published>2018-06-25T13:16:57.090Z</published>
    <updated>2018-06-25T13:58:25.816Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十六篇原创文章
</code></pre><p>简直是神器啊  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/dIxaOYj.png" alt=""></p>
<a id="more"></a>
<p>今天在翻莫烦大大的博客时，看到他提到一个工具，便去看了下，第一感受是，太好用了、爱不释手。</p>
<p>下面来说说这个工具：Katalon Recorder</p>
<h1 id="Katalon-Recorder"><a href="#Katalon-Recorder" class="headerlink" title="Katalon Recorder"></a>Katalon Recorder</h1><p>安装地址：<a href="https://chrome.google.com/webstore/detail/katalon-recorder-selenium/ljdobmomdgdljniojadhoplhkpialdid/related" target="_blank" rel="external">Katalon Recorder</a></p>
<p>官方介绍是：</p>
<blockquote>
<p>Best Selenium IDE record, play, debug app. Exports Selenium WebDriver code. Provides reports, logs, screenshots. Fast &amp; extensible. </p>
</blockquote>
<p>简单来说，他可以记录你在浏览器上的每一个动作，包括、点击、输入、输入字符等等，最后一键转化为编程代码，可以转化的语言有：</p>
<ol>
<li>C#</li>
<li>JAVA</li>
<li>Katalon Studio</li>
<li>Python2</li>
<li>Roboot Framework</li>
<li>Ruby</li>
<li>XML</li>
</ol>
<p>例如下图就是直接转化为 Python2的代码</p>
<p><img src="https://i.imgur.com/q6t07p3.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</div><div class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</div><div class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</div><div class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> Select</div><div class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException</div><div class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoAlertPresentException</div><div class="line"><span class="keyword">import</span> unittest, time, re</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UntitledTestCase</span><span class="params">(unittest.TestCase)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUp</span><span class="params">(self)</span>:</span></div><div class="line">        self.driver = webdriver.Firefox()</div><div class="line">        self.driver.implicitly_wait(<span class="number">30</span>)</div><div class="line">        self.base_url = <span class="string">"https://www.katalon.com/"</span></div><div class="line">        self.verificationErrors = []</div><div class="line">        self.accept_next_alert = <span class="keyword">True</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_untitled_test_case</span><span class="params">(self)</span>:</span></div><div class="line">        driver = self.driver</div><div class="line">        driver.get(<span class="string">"https://zhangslob.github.io/"</span>)</div><div class="line">        driver.find_element_by_link_text(<span class="string">u"Cookies池的后续解决方案"</span>).click()</div><div class="line">        driver.find_element_by_xpath(<span class="string">"//main[@id='main']/div/div"</span>).click()</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_element_present</span><span class="params">(self, how, what)</span>:</span></div><div class="line">        <span class="keyword">try</span>: self.driver.find_element(by=how, value=what)</div><div class="line">        <span class="keyword">except</span> NoSuchElementException <span class="keyword">as</span> e: <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">True</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_alert_present</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">try</span>: self.driver.switch_to_alert()</div><div class="line">        <span class="keyword">except</span> NoAlertPresentException <span class="keyword">as</span> e: <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">True</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_alert_and_get_its_text</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            alert = self.driver.switch_to_alert()</div><div class="line">            alert_text = alert.text</div><div class="line">            <span class="keyword">if</span> self.accept_next_alert:</div><div class="line">                alert.accept()</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                alert.dismiss()</div><div class="line">            <span class="keyword">return</span> alert_text</div><div class="line">        <span class="keyword">finally</span>: self.accept_next_alert = <span class="keyword">True</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tearDown</span><span class="params">(self)</span>:</span></div><div class="line">        self.driver.quit()</div><div class="line">        self.assertEqual([], self.verificationErrors)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    unittest.main()</div></pre></td></tr></table></figure>
<p>虽然说用的是Python2，但是并不影响，简单改一下就就可以使用了，主要逻辑在<code>test_untitled_test_case</code>函数中，可以直接拿来使用。</p>
<p>注意这里使用了<code>unittest</code>，不熟悉的可以来看看<a href="https://docs.python.org/3/library/unittest.html" target="_blank" rel="external">文档</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> unittest</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestStringMethods</span><span class="params">(unittest.TestCase)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_upper</span><span class="params">(self)</span>:</span></div><div class="line">        self.assertEqual(<span class="string">'foo'</span>.upper(), <span class="string">'FOO'</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_isupper</span><span class="params">(self)</span>:</span></div><div class="line">        self.assertTrue(<span class="string">'FOO'</span>.isupper())</div><div class="line">        self.assertFalse(<span class="string">'Foo'</span>.isupper())</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_split</span><span class="params">(self)</span>:</span></div><div class="line">        s = <span class="string">'hello world'</span></div><div class="line">        self.assertEqual(s.split(), [<span class="string">'hello'</span>, <span class="string">'world'</span>])</div><div class="line">        <span class="comment"># check that s.split fails when the separator is not a string</span></div><div class="line">        <span class="keyword">with</span> self.assertRaises(TypeError):</div><div class="line">            s.split(<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    unittest.main()</div></pre></td></tr></table></figure>
<h1 id="安装方法"><a href="#安装方法" class="headerlink" title="安装方法"></a>安装方法</h1><p>这里建议直接在Chrome应用市场安装，地址 <a href="https://chrome.google.com/webstore/detail/katalon-recorder-selenium/ljdobmomdgdljniojadhoplhkpialdid/related" target="_blank" rel="external">Katalon Recorder</a></p>
<p>考虑到有些同学可能那啥，所以我已经下载好了。公众号：Python爬虫与算法进阶，回复：<strong>傻瓜</strong></p>
<p><img src="https://i.imgur.com/93kxeCD.jpg" alt=""></p>
<h1 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h1><p>这个相当于按键精灵，把我们对浏览器的每一步操作都完成了，可以用来生成代码，和postman一样，所以我才会说 <code>Katalon + 傻瓜 == selenium</code>，完全是傻瓜操作。</p>
<p>比如来做一些自动化登录、注册等板块会非常爽，但是验证码部分还是需要自行解决。</p>
<p>但是该软件也是有一些问题的，它不能进行多页面切换，也就是不能自动切换到新打开的窗口，会有错误提示<code># ERROR: Caught exception [ERROR: Unsupported command [selectWindow | win_ser_1 | ]]</code>，这一步必须自己手动来操作，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">driver.current_window_handle 获取当前窗口handle</div><div class="line">driver.window_handles 获取所有窗口的handle，返回list列表</div><div class="line">driver.switch_to.window(handle) 切换到对应的窗口</div><div class="line">driver.close() 关闭当前窗口</div></pre></td></tr></table></figure>
<p>测试打开多窗口的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</div><div class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</div><div class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</div><div class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> Select</div><div class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException</div><div class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoAlertPresentException</div><div class="line"><span class="keyword">import</span> unittest, time, re</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Zhihu</span><span class="params">(unittest.TestCase)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUp</span><span class="params">(self)</span>:</span></div><div class="line">        self.driver = webdriver.Firefox()</div><div class="line">        self.driver.implicitly_wait(<span class="number">30</span>)</div><div class="line">        self.base_url = <span class="string">"https://www.katalon.com/"</span></div><div class="line">        self.verificationErrors = []</div><div class="line">        self.accept_next_alert = <span class="keyword">True</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_zhihu</span><span class="params">(self)</span>:</span></div><div class="line">        driver = self.driver</div><div class="line">        driver.get(<span class="string">"https://www.zhihu.com/people/cuishite/activities"</span>)</div><div class="line">        driver.find_element_by_xpath(<span class="string">"//div[@id='ProfileMain']/div/ul/li[2]/a"</span>).click()</div><div class="line">        driver.find_element_by_xpath(<span class="string">"//div[@id='ProfileMain']/div/ul/li[4]/a/span"</span>).click()</div><div class="line">        driver.find_element_by_link_text(<span class="string">u"Cookies池的后续解决方案"</span>).click()</div><div class="line">        <span class="comment"># ERROR: Caught exception [ERROR: Unsupported command [selectWindow | win_ser_1 | ]]</span></div><div class="line">        driver.find_element_by_xpath(<span class="string">"//img[contains(@src,'https://pic4.zhimg.com/v2-7ff26e52e6c82c080f62d8e9291e532b_b.jpg')]"</span>).click()</div><div class="line">        driver.find_element_by_link_text(<span class="string">u"Cookies池的后续解决方案"</span>).click()</div><div class="line">        <span class="comment"># ERROR: Caught exception [ERROR: Unsupported command [selectWindow | win_ser_2 | ]]</span></div><div class="line">        driver.find_element_by_xpath(<span class="string">"//div[@id='js_article']/div[2]"</span>).click()</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_element_present</span><span class="params">(self, how, what)</span>:</span></div><div class="line">        <span class="keyword">try</span>: self.driver.find_element(by=how, value=what)</div><div class="line">        <span class="keyword">except</span> NoSuchElementException <span class="keyword">as</span> e: <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">True</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_alert_present</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">try</span>: self.driver.switch_to_alert()</div><div class="line">        <span class="keyword">except</span> NoAlertPresentException <span class="keyword">as</span> e: <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">True</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_alert_and_get_its_text</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            alert = self.driver.switch_to_alert()</div><div class="line">            alert_text = alert.text</div><div class="line">            <span class="keyword">if</span> self.accept_next_alert:</div><div class="line">                alert.accept()</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                alert.dismiss()</div><div class="line">            <span class="keyword">return</span> alert_text</div><div class="line">        <span class="keyword">finally</span>: self.accept_next_alert = <span class="keyword">True</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tearDown</span><span class="params">(self)</span>:</span></div><div class="line">        self.driver.quit()</div><div class="line">        self.assertEqual([], self.verificationErrors)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    unittest.main()</div></pre></td></tr></table></figure>
<p>所以只需要这一点就可以完善代码，同时可以看看他们的官网 <a href="https://www.katalon.com/" target="_blank" rel="external">KATALON - Best automated testing tool for web, mobile, API</a>，他们主要是提供测试工具，感兴趣的可以了解下。</p>
<p><img src="https://i.imgur.com/V8smLse.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十六篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;简直是神器啊  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/dIxaOYj.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>Cookies池的后续解决方案</title>
    <link href="https://zhangslob.github.io/2018/06/16/Cookies%E6%B1%A0%E7%9A%84%E5%90%8E%E7%BB%AD%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://zhangslob.github.io/2018/06/16/Cookies池的后续解决方案/</id>
    <published>2018-06-16T07:01:54.000Z</published>
    <updated>2018-06-16T07:05:36.039Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十五篇原创文章
</code></pre><p>终于有方法了  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/VD9q71g.jpg" alt=""></p>
<a id="more"></a>
<p><img src="https://i.imgur.com/VD9q71g.jpg" alt=""></p>
<p><img src="http://ww1.sinaimg.cn/bmiddle/76a1b64dly1fschugfmkfg20a905savu.gif" alt=""></p>
<blockquote>
<p>作为一名罗吹,先吹一波C罗牛皮,简直太帅了了了</p>
<p>瞧瞧这个眼神<br>建议大家可以看看这场比赛，西班牙VS葡萄牙，我相信你会爱上足球的</p>
</blockquote>
<h1 id="正文开始"><a href="#正文开始" class="headerlink" title="正文开始"></a>正文开始</h1><p>在上一篇文章: 简单说明了自己对于该网站的想法,在经过两天的测试与研究之后,我有了更多的想法.</p>
<h2 id="想法一-为每个Cookies绑定唯一IP"><a href="#想法一-为每个Cookies绑定唯一IP" class="headerlink" title="想法一: 为每个Cookies绑定唯一IP"></a>想法一: 为每个Cookies绑定唯一IP</h2><p>你作为一个普通用户,如果对方网站检测到你不停地变换IP从不同地方来发送请求,那他肯定会有识别.那么我们可以把每一个Cookies分配唯一的IP代理,也就是你这个Cookies发送请求的代理始终是唯一的.</p>
<p>但是这种方法的实现方式还没有想出来,不知道该使用哪些技术栈来实现这个想法</p>
<h2 id="想法二-解决验证码"><a href="#想法二-解决验证码" class="headerlink" title="想法二: 解决验证码"></a>想法二: 解决验证码</h2><p>好,既然你弹出验证码,那我就解决它! 解决方法是:</p>
<ol>
<li>该网站的验证码图片是<code>base64</code>,用<code>python</code>转一下,接上第三方就OK</li>
<li>同时该网站参数中还带有<code>token</code>参数,经过前端大佬的断点调试,发现是对多个字段的两次加密</li>
<li>保持会话session.你需要让对方网站知道是你这个用户,所以你的cookies,ip,headers相关信息必须保持一致,我当时的想法是使用<code>requests</code>的<code>session</code>来完成这一步操作,但是很难完全模拟,因为整个爬虫使用<code>scrapy</code>来写,处理验证码使用<code>requests</code>来做,<code>session</code>这部分不大好模拟.</li>
</ol>
<p>附上一些为<code>session</code>添加信息的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, my_cookie, proxy, headers)</span>:</span></div><div class="line">    self.session = requests.session()</div><div class="line">    self.session.cookies.update(my_cookie)</div><div class="line">    self.session.headers.update(&#123;<span class="string">'User-Agent'</span>: headers&#125;)</div><div class="line">    self.session.update(proxy)</div></pre></td></tr></table></figure>
<h2 id="想法三-不解决验证问题-无脑重试"><a href="#想法三-不解决验证问题-无脑重试" class="headerlink" title="想法三: 不解决验证问题,无脑重试"></a>想法三: 不解决验证问题,无脑重试</h2><p>这是最蠢的办法,也是我目前在使用的方法. /(ㄒoㄒ)/~~</p>
<p>思路是: 将<code>cookies</code>保存到mongoDB做持久化,再写一个脚本,持续的向<code>redis</code>中添加<code>cookies</code>和<code>start_urls</code>,然后对这些<code>start_urls</code>不停地重试,对,就是不停地重试,直到把所有的链接跑完.本次需要采集的链接并不多,质量要求不高,只需要我采集到数据就好.</p>
<p>需要注意的是:</p>
<ol>
<li>需要为你的表增加唯一键,不然会有重复数据</li>
<li>每条请求添加<code>dont_filter=True</code>,不然去重会影响爬取</li>
</ol>
<p>添加<code>cookies</code>和<code>start_urls</code>代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># add cookies and start_urls to local_redis</span></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="keyword">if</span> local_redis.scard(<span class="string">'spider:cookies'</span>) &lt; <span class="number">10</span>:</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> cookies_list:</div><div class="line">            local_redis.sadd(<span class="string">'spider:cookies'</span>, i)</div><div class="line">        print(<span class="string">"cookies Done"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> local_redis.scard(<span class="string">'spider:start_urls'</span>) &lt; <span class="number">10</span>:</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> url_list:</div><div class="line">            local_redis.sadd(<span class="string">'spider:start_urls'</span>, i)</div><div class="line">        print(<span class="string">"start_urls Done"</span>)</div><div class="line">        </div><div class="line">    time.sleep(<span class="number">10</span>)</div></pre></td></tr></table></figure>
<h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><p>我是用的是第三种方法,目前看来效果还行,数据已经爬取了大半,相信三天假过去了应该就没问题了.</p>
<p>如果以后要长期做这个项目的话,最好的办法应该还是第二种,从根本去解决问题.</p>
<p>本次做这个项目也收获颇多,对于<code>cookies</code>使用更加有经验;感觉最好玩的是<code>token</code>的加密与解密实现,对这方面感兴趣的可以了解下这个: <a href="https://docs.python.org/3/library/zlib.html" target="_blank" rel="external">zlib — Compression compatible with gzip</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十五篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;终于有方法了  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/VD9q71g.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="cookie池" scheme="https://zhangslob.github.io/tags/cookie%E6%B1%A0/"/>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>从cookie池搭建说起</title>
    <link href="https://zhangslob.github.io/2018/06/14/%E4%BB%8Ecookie%E6%B1%A0%E6%90%AD%E5%BB%BA%E8%AF%B4%E8%B5%B7/"/>
    <id>https://zhangslob.github.io/2018/06/14/从cookie池搭建说起/</id>
    <published>2018-06-14T13:25:46.000Z</published>
    <updated>2018-06-14T14:33:09.507Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十四篇原创文章
</code></pre><p>我快绝望了  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/ZJMuGd5.jpg" alt=""></p>
<a id="more"></a>
<p>这几天接手了一个很急的项目，要在几天爬取某网站的数据。该站是我知道国内反爬比较严重的网站之一，我也做好了心理准备。</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1528996797209&amp;di=3836d0c6faff25ec236862e1eae20486&amp;imgtype=0&amp;src=http%3A%2F%2Fkibey-echo.b0.upaiyun.com%2Fposter%2F2014%2F09%2F24%2Fbd9ba222cb5a1e9e.gif" alt=""></p>
<h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>该网站数据需要登录才能查看，APP抓包了但是没有发现相关数据，所以选择从PC站入手。</p>
<p>既然需要登录，那就需要验证一个新鲜的<code>cookies</code>可以访问多少链接；验证方法是：</p>
<blockquote>
<p>直接拷贝已经登录该网站请求的Curl，转换为Python代码，加一个循环，测试，单个账号可以跑多少页</p>
</blockquote>
<p>经过10多次测试，发现单个Cookies可以下载，至少50个网页。</p>
<p>那么就很好做了，可以开始写思路了。</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1528996828313&amp;di=58be2c7592bc5f2f35ac0df4e513234f&amp;imgtype=0&amp;src=http%3A%2F%2Fcdnq.duitang.com%2Fuploads%2Fitem%2F201507%2F10%2F20150710172216_LtFrM.thumb.700_0.jpeg" alt=""></p>
<h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>首先我们需要多个可以登录的Cookies，然后利用这些Cookies去下载网页；一旦返回状态码不是200，就拉黑该Cookies。</p>
<p>具体的方法看下图：</p>
<p><img src="https://i.imgur.com/7uqitsi.png" alt=""></p>
<p>有几点说明下：</p>
<ol>
<li><strong>如何模拟注册</strong>。有两种方法，<strong>模拟请求</strong>和<strong>浏览器模拟</strong>。模拟请求就是去分析注册过程中的每一步操作，这个请求是发送验证码的，那个是注册的，我优先推荐该方法，但是这种方法遇到一些携带有大量签名参数的变态网站时，难度较大，需要自己一步步断点<code>JavaScript</code>。浏览器模拟大家应该很熟悉，Python中就是<code>selenium</code>傻瓜操作，需要哪里点哪里。注意的坑是何时切换<code>iframe</code></li>
<li><strong>Cookies的搭建</strong>。其实非常简单，这里利用了<code>redis</code>的集合，取Cookies使用<code>spop</code>即可。这里并没有做验活，因为基本上Cookies产生之后就会被使用。</li>
</ol>
<h1 id="我要崩溃了"><a href="#我要崩溃了" class="headerlink" title="我要崩溃了"></a>我要崩溃了</h1><p>不做不知道，一做吓一跳。</p>
<p>但我以为该网站很简单，搭建一个简单的Cookies池就可以解决，但是我明显太年轻了。</p>
<p>我先把采集链接推到<code>redis</code>中，使用了<code>scrapy_redis</code>。</p>
<p>该网站的反爬：</p>
<ol>
<li><strong>代理问题</strong>。其实这里有一个悖论，到底该不该使用代理。首先，我不用代理，刚开始还好，但是很快我的本地代理就被拉黑了；那好上代理，但是接下来问题来了，开始出现一个个的验证码需要填了，作为一个<strong>单独的用户</strong>，我是不可能频繁的改变自己的<code>IP</code>去访问网站的，解决方法只有一个，Cookies和代理绑定，但是这种方法真的不好实现，尤其是使用<code>Scrapy</code>开发的爬虫。</li>
<li><strong>验证码问题</strong>。既然出现了验证码，那就去解决它。验证码一般是和Cookies绑定的，那么我需要把访问该账号的<code>IP</code>、<code>User-Agent</code>、<code>Cookies</code>全部拿出来，再去发送新的请求，而且需要注意，此过程中不能再进行<code>IP</code>的变化。</li>
</ol>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>今天了大概两天的斗智斗勇，现在基本上可以爬到数据了，希望明天可以交差，不然端午就要加班了。</p>
<p>希望这只小猫咪可以给我带来好远。</p>
<p><img src="https://i.imgur.com/vWSjxX9.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十四篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我快绝望了  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ZJMuGd5.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="cookie池" scheme="https://zhangslob.github.io/tags/cookie%E6%B1%A0/"/>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>为了知道胡歌粉丝的男女比率，爬了三百万微博数据</title>
    <link href="https://zhangslob.github.io/2018/06/07/%E8%83%A1%E6%AD%8C%E7%94%B7%E7%B2%89%E5%A4%9A%E8%BF%98%E6%98%AF%E5%A5%B3%E7%B2%89%E5%A4%9A-%E7%88%AC%E7%88%AC%E5%BE%AE%E5%8D%9A/"/>
    <id>https://zhangslob.github.io/2018/06/07/胡歌男粉多还是女粉多-爬爬微博/</id>
    <published>2018-06-07T13:59:53.000Z</published>
    <updated>2018-06-10T08:04:50.610Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十三篇原创文章
</code></pre><p>老胡好帅  (๑• . •๑)</p>
<p><img src="http://wx1.sinaimg.cn/large/48e837eely1fmhxeqwby0j22ds1sg157.jpg" alt=""></p>
<a id="more"></a>
<p>最近偶然间看到一条新闻，标题是：“胡歌作为一个男性明星，男粉丝比女粉丝还多，这不科学！”</p>
<p><img src="https://i.imgur.com/959B59J.png" alt=""></p>
<p>文中这样说道“胡歌在微博上的粉丝就已经达到了5748.9398万人，并且通过查看粉丝可以发现许多都是男性粉丝，这不得不说这是独一无二了”</p>
<p>当时我就震惊了，“通过查看粉丝”？？？这是什么操作，现在的UC小编越来越多了吗？</p>
<p>我作为一名老胡的粉丝，简直是不能忍，这完全是在瞎写啊。</p>
<p>所以我有个想法，把胡歌微博上六千万粉丝数据爬取下来，看看到底男粉丝多还是女粉丝多。</p>
<blockquote>
<p>大家可以在自己心中猜测一个答案，到底男粉多还是女粉多呢～～。我的答案是男性比较多。</p>
</blockquote>
<h1 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h1><p><img src="https://i.imgur.com/h1TyXZ7.png" alt=""></p>
<p>这里可以看到胡歌微博粉丝总数约6千万，本次我的目标就是尽力去找到胡歌<strong>活跃粉丝</strong>的男女比例。</p>
<p>但是我们知道微博是有限制的，微博不会把所有数据都展示出来，如图</p>
<p><img src="https://i.imgur.com/UxASfy6.png" alt=""></p>
<p>那么问题来了，我要怎样才能尽可能多的抓到粉丝数据？</p>
<p>这里我就想要尽可能多的抓取到老胡的活跃粉丝， 所谓活跃粉丝，指的是除去“不转发、不评论、不点赞”这些“三不”用户，是活跃的、有参与的用户。这些用户才是真正有价值的，正好去除了僵尸粉。</p>
<h1 id="两种思路"><a href="#两种思路" class="headerlink" title="两种思路"></a>两种思路</h1><p>采集微博粉丝，目前我有两种方法来解决这个问题，：</p>
<ol>
<li>全量采集。采集微博所有用户数据，包括关注、粉丝等。通过粉丝的粉丝、关注的关注、用户分类、推荐等等各种方法拿到微博全量用户数据。</li>
<li>采样。采集胡歌的所有微博下有评论、点赞、转发的用户，凡是有参与过的亲密值加一，当这个值超过一定限度时（比如说5或者10），我们就认为该用户是胡歌的粉丝。</li>
</ol>
<p>想了想，第一种方法短时间内是不现实的，方法2倒是可以尝试一波。</p>
<h1 id="爬虫逻辑"><a href="#爬虫逻辑" class="headerlink" title="爬虫逻辑"></a>爬虫逻辑</h1><p>爬虫分为三步：</p>
<ol>
<li>采集胡歌所有微博</li>
<li>采集每条微博的三类数据（转发、评论、点赞）</li>
<li>数据清洗</li>
</ol>
<p>好了，现在已经非常清晰了，下面就开始去寻找爬取方法。</p>
<h1 id="微博接口"><a href="#微博接口" class="headerlink" title="微博接口"></a>微博接口</h1><p>根据以往的经验，weibo.cn 和 m.weibo.cn 是最简单爬取的，weibo.com 是最难的。这次我们从 m.weibo.cn 入手，分析可以得到胡歌微博的接口，而且是无需登录的！！！很重要。其他入口都需要解决登录难题！</p>
<p><code>https://m.weibo.cn/api/container/getIndex?containerid=1076031223178222&amp;page={}</code></p>
<p>返回数据：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function">cardlistInfo: &#123;</span></div><div class="line"><span class="title">containerid</span>: "1076031223178222",</div><div class="line"><span class="title">v_p</span>: 42,</div><div class="line"><span class="title">show_style</span>: 1,</div><div class="line"><span class="title">total</span>: 3643,</div><div class="line"><span class="title">page</span>: 2</div><div class="line">&#125;,</div></pre></td></tr></table></figure>
<p>这里告诉我们总共有3643条数据，每页10条，那么翻页就很清晰了。</p>
<h2 id="其他接口"><a href="#其他接口" class="headerlink" title="其他接口"></a>其他接口</h2><figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">转发：https://m.weibo.cn/api/statuses/repostTimeline?id=<span class="number">4238119278366780</span>&amp;page=&#123;&#125;</div><div class="line"></div><div class="line">评论：https://m.weibo.cn/api/comments/show?id=<span class="number">4238119278366780</span>&amp;page=&#123;&#125;</div><div class="line"></div><div class="line">点赞：https://m.weibo.cn/api/attitudes/show?id=<span class="number">4238119278366780</span>&amp;page=&#123;&#125;</div></pre></td></tr></table></figure>
<p>（想要爬其他人，替换这里的id即可）</p>
<p>暂时不清楚总共有多少页，虽然返回的数据中有 <code>total_number</code> ，但是此数字并不准确，还需要更多测试。</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function">total_number: 19526897,</span></div><div class="line"><span class="title">hot_total_number</span>: 0,</div><div class="line"><span class="title">max</span>: 1952690</div></pre></td></tr></table></figure>
<p>（简单测后发现总页数为<code>total_number//55</code>）</p>
<h2 id="采集用户信息接口"><a href="#采集用户信息接口" class="headerlink" title="采集用户信息接口"></a>采集用户信息接口</h2><p><code>https://m.weibo.cn/api/container/getIndex?type=uid&amp;value=6114792181</code></p>
<p>其实不需要这一次请求，因为在转发接口中已经有我们想要的数据了，如下：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function">user: &#123;</span></div><div class="line"><span class="title">id</span>: 6431898981,</div><div class="line"><span class="title">screen_name</span>: "豪气<span class="title">superiority</span>",</div><div class="line"><span class="title">profile_image_url</span>: "<span class="title">https</span>://<span class="title">tvax2.sinaimg.cn</span>/<span class="title">crop</span>.9.0.220.220.180/0071<span class="title">hAK9ly8fmdxpea2vxj306n064glj.jpg</span>",</div><div class="line"><span class="title">profile_url</span>: "<span class="title">https</span>://<span class="title">m.weibo.cn</span>/<span class="title">u</span>/6431898981?<span class="title">uid</span>=6431898981&amp;<span class="title">featurecode</span>=20000320",</div><div class="line"><span class="title">statuses_count</span>: 7255,</div><div class="line"><span class="title">verified</span>: <span class="title">false</span>,</div><div class="line"><span class="title">verified_type</span>: -1,</div><div class="line"><span class="title">close_blue_v</span>: <span class="title">false</span>,</div><div class="line"><span class="title">description</span>: "",</div><div class="line"><span class="title">gender</span>: "<span class="title">m</span>",</div><div class="line"><span class="title">mbtype</span>: 0,</div><div class="line"><span class="title">urank</span>: 4,</div><div class="line"><span class="title">mbrank</span>: 0,</div><div class="line"><span class="title">follow_me</span>: <span class="title">false</span>,</div><div class="line"><span class="title">following</span>: <span class="title">false</span>,</div><div class="line"><span class="title">followers_count</span>: 2,</div><div class="line"><span class="title">follow_count</span>: 62,</div><div class="line"><span class="title">cover_image_phone</span>: "<span class="title">https</span>://<span class="title">tva1.sinaimg.cn</span>/<span class="title">crop</span>.0.0.640.640.640/549<span class="title">d0121tw1egm1kjly3jj20hs0hsq4f.jpg</span>",</div><div class="line"><span class="title">avatar_hd</span>: "<span class="title">https</span>://<span class="title">wx2.sinaimg.cn</span>/<span class="title">orj480</span>/0071<span class="title">hAK9ly8fmdxpea2vxj306n064glj.jpg</span>",</div><div class="line"><span class="title">like</span>: <span class="title">false</span>,</div><div class="line"><span class="title">like_me</span>: <span class="title">false</span>,</div><div class="line"><span class="title">badge</span>: &#123;</div><div class="line"><span class="title">user_name_certificate</span>: 1,</div><div class="line"><span class="title">wenchuan_10th</span>: 1</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>很蛋疼的是，点赞和评论接口中并没有相关数据，所以点赞和评论部分要重新爬取，如下：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line"><span class="function">id: 4247512245791226,</span></div><div class="line"><span class="title">created_at</span>: "5分钟前",</div><div class="line"><span class="title">source</span>: "微博 <span class="title">weibo.com</span>",</div><div class="line"><span class="title">user</span>: &#123;</div><div class="line"><span class="title">id</span>: 6114792181,</div><div class="line"><span class="title">screen_name</span>: "<span class="title">Ming_54456</span>",</div><div class="line"><span class="title">profile_image_url</span>: "<span class="title">https</span>://<span class="title">tvax1.sinaimg.cn</span>/<span class="title">crop</span>.367.164.918.918.180/006<span class="title">FP2Mlly8fjs2mf3x6pj319x0yoqbo.jpg</span>",</div><div class="line"><span class="title">verified</span>: <span class="title">false</span>,</div><div class="line"><span class="title">verified_type</span>: -1,</div><div class="line"><span class="title">mbtype</span>: 12,</div><div class="line"><span class="title">profile_url</span>: "<span class="title">https</span>://<span class="title">m.weibo.cn</span>/<span class="title">u</span>/6114792181?<span class="title">uid</span>=6114792181&amp;<span class="title">featurecode</span>=20000320",</div><div class="line"><span class="title">remark</span>: "",</div><div class="line"><span class="title">following</span>: <span class="title">false</span>,</div><div class="line"><span class="title">follow_me</span>: <span class="title">false</span></div><div class="line">&#125;</div><div class="line">&#125;,</div></pre></td></tr></table></figure>
<p>微博官方API同样提供相应数据 ，建议使用前仔细阅读 <a href="http://open.weibo.com/wiki/Rate-limiting" target="_blank" rel="external">接口访问频次权限</a></p>
<h1 id="爬虫代码"><a href="#爬虫代码" class="headerlink" title="爬虫代码"></a>爬虫代码</h1><p>爬虫完整代码可以去我的公众号（Python爬虫与算法进阶），回复“微博”获得。</p>
<p>爬虫语言是Python3，使用Scrapy框架，数据保存在mongo，没有使用分布式，单机3天跑完。</p>
<p>因为微博的反爬，需要大量代理支撑。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># code is far away from bugs with the god animal protecting</span></div><div class="line">    I love animals. They taste delicious.</div><div class="line">              ┏┓      ┏┓</div><div class="line">            ┏┛┻━━━┛┻┓</div><div class="line">            ┃      ☃      ┃</div><div class="line">            ┃  ┳┛  ┗┳  ┃</div><div class="line">            ┃      ┻      ┃</div><div class="line">            ┗━┓      ┏━┛</div><div class="line">                ┃      ┗━━━┓</div><div class="line">                ┃  神兽保佑    ┣┓</div><div class="line">                ┃　永无BUG！   ┏┛</div><div class="line">                ┗┓┓┏━┳┓┏┛</div><div class="line">                  ┃┫┫  ┃┫┫</div><div class="line">                  ┗┻┛  ┗┻┛</div></pre></td></tr></table></figure>
<p>爬取的数据实例：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    "_id" : ObjectId("<span class="number">5</span>b162d10e0eafb1d6e63b460"),</div><div class="line">    "id" : NumberLong(<span class="number">5372682651</span>),</div><div class="line">    "statuses_count" : <span class="number">10599</span>,</div><div class="line">    "screen_name" : "用户<span class="number">5372682651</span>",</div><div class="line">    "profile_url" : "https://m.weibo.cn/u/<span class="number">5372682651</span>?uid=<span class="number">5372682651</span>",</div><div class="line">    "description" : "暂无数据",</div><div class="line">    "gender" : "f",</div><div class="line">    "followers_count" : <span class="number">80</span>,</div><div class="line">    "follow_count" : <span class="number">1060</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="简单数据清洗"><a href="#简单数据清洗" class="headerlink" title="简单数据清洗"></a>简单数据清洗</h1><p>最终跑完一次爬到的数据有<code>3889285</code>，因为有大量页面会跳转到登录页面，对这些请求做一个重试效果会好些。</p>
<p>数据清洗对我来说真的是个头疼的问题，找了很多相关资料，最后使用了mongo的<code>aggregate</code>方法，该方法也是我第一次使用，下面是代码：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">db.getCollection('Weibo').aggregate(</div><div class="line">    [</div><div class="line">        &#123;"$group" : &#123;_id:&#123;id:"$id",gender:"$gender"&#125;, count:&#123;$sum:<span class="number">1</span>&#125;&#125;&#125;,</div><div class="line">        &#123;$sort:&#123;"count":-<span class="number">1</span>&#125;&#125;,</div><div class="line">        &#123; $out:"result"&#125;,</div><div class="line">    ],</div><div class="line">    &#123;</div><div class="line"><span class="function">      allowDiskUse:<span class="title">true</span>,</span></div><div class="line">      <span class="title">cursor</span>:&#123;&#125;</div><div class="line">    &#125;  </div><div class="line">)</div></pre></td></tr></table></figure>
<p>结果产生了一张新的表，对每个ID进行统计，并排序，如下：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    "_id" : &#123;</div><div class="line">        "id" : NumberLong(<span class="number">5737668415</span>),</div><div class="line">        "gender" : "f"</div><div class="line">    &#125;,</div><div class="line">    "count" : <span class="number">106701</span>.<span class="number">0</span></div><div class="line">&#125;</div><div class="line">&#123;</div><div class="line">    "_id" : &#123;</div><div class="line">        "id" : NumberLong(<span class="number">5909154992</span>),</div><div class="line">        "gender" : "m"</div><div class="line">    &#125;,</div><div class="line">    "count" : <span class="number">72298</span>.<span class="number">0</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>参与次数达到十万次，天呐，超级真爱粉，<a href="https://m.weibo.cn/u/5737668415?uid=5737668415" target="_blank" rel="external">缘来是她</a>，疯狂刷屏有没有</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180607110639.png" alt=""></p>
<p>好了，现在开始看看真正的数据吧。</p>
<p>本次共采集用户数据<code>3889285</code>条，，原始数据中男性占比<code>%33.68</code>，女性占比<code>%66.32</code>，好吧，看来女性粉丝更多；去重之后数据共有<code>1129035</code>，男性占比<code>%29.58</code>，女性占比<code>%70.42</code>，怎么看着女性粉丝还是更多呢。。</p>
<p>我们再来计算一个数据，亲密度大于10的粉丝共有<code>16486</code>位，其中男性占比<code>%24.05</code>，女性占比<code>%75.95</code>，于是有下面这张表格。</p>
<table>
<thead>
<tr>
<th style="text-align:left">亲密度</th>
<th>男性占比</th>
<th>女性占比</th>
<th>粉丝总数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">大于0</td>
<td>29.58%</td>
<td>70.42%</td>
<td>1129035</td>
</tr>
<tr>
<td style="text-align:left">大于10</td>
<td>24.05%</td>
<td>75.95%</td>
<td>16486</td>
</tr>
<tr>
<td style="text-align:left">大于50</td>
<td>32.77%</td>
<td>67.23%</td>
<td>4285</td>
</tr>
<tr>
<td style="text-align:left">大于100</td>
<td>36.77%</td>
<td>63.23%</td>
<td>2578</td>
</tr>
<tr>
<td style="text-align:left">大于1000</td>
<td>40.18%</td>
<td>59.82%</td>
<td>331</td>
</tr>
<tr>
<td style="text-align:left">大于10000</td>
<td>37.5%</td>
<td>62.5%</td>
<td>24</td>
</tr>
<tr>
<td style="text-align:left">Top10</td>
<td>30.00%</td>
<td>70.00%</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>这个数据挺有意思的，画张表瞧瞧</p>
<p><img src="https://i.loli.net/2018/06/10/5b1cd33ba3031.png" alt=""></p>
<p>粉丝昵称词云</p>
<p><img src="https://i.loli.net/2018/06/10/5b1cd793e1520.png" alt=""></p>
<p>（感谢BDP）</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>看了这些数据，相信大家自己心中已经有了答案。</p>
<p>胡歌作为一个玉树临风、 英俊潇洒、 风流倜傥、 一表人才、 高大威猛、 气宇不凡、 温文尔雅、 品貌非凡、 仪表不凡的男人，女粉丝比较多是很正常的。但是为啥大家都会有一种男粉丝比女粉丝多的错觉呢，我觉得是对比产生的感觉。我拿胡歌与其他小鲜肉作对比，肯定会跟欣赏胡歌。你说呢？</p>
<p>本文并不是为了证明什么，只是作为一名普通粉丝想去看看更多东西。其实本次数据爬取有很多地方需要优化，大家不用太过当真。如果你有更好的分析数据的想法，可以联系我。</p>
<blockquote>
<p>老大镇楼</p>
</blockquote>
<p><img src="http://wx1.sinaimg.cn/large/48e837eegy1fe2dmkfsquj21tq1tqu0x.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十三篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;老胡好帅  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/large/48e837eely1fmhxeqwby0j22ds1sg157.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="胡歌" scheme="https://zhangslob.github.io/tags/%E8%83%A1%E6%AD%8C/"/>
    
      <category term="微博" scheme="https://zhangslob.github.io/tags/%E5%BE%AE%E5%8D%9A/"/>
    
  </entry>
  
  <entry>
    <title>zsh(+fish)=完美终端</title>
    <link href="https://zhangslob.github.io/2018/06/05/zsh-fish-%E5%AE%8C%E7%BE%8E%E7%BB%88%E7%AB%AF/"/>
    <id>https://zhangslob.github.io/2018/06/05/zsh-fish-完美终端/</id>
    <published>2018-06-05T14:27:23.000Z</published>
    <updated>2018-06-05T14:35:15.770Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十二篇原创文章
</code></pre><p>好看、好用  (๑• . •๑)</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180605191928.png" alt=""></p>
<a id="more"></a>
<p>自从用了深度，有一个非常明显的变化就是终端的改变，实在是比windows的好用一百倍，尤其是使用一些工具。下面说说我现在的配置。</p>
<p>如下图，是我目前正在使用的终端，集成了zsh和fish的功能，目前用着最顺手的。</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180605190132.png" alt=""></p>
<p><a href="https://github.com/robbyrussell/oh-my-zsh" target="_blank" rel="external">https://github.com/robbyrussell/oh-my-zsh</a></p>
<h1 id="安装zsh"><a href="#安装zsh" class="headerlink" title="安装zsh"></a>安装zsh</h1><p>一般来说，直接运行<code>sudo apt-get install zsh</code>即可，当然也可以下载源<a href="http://zsh.sourceforge.net/Arc/source.html" target="_blank" rel="external">Download zsh source</a>，使用curl安装<code>curl -L &lt;https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh&gt; | sh</code></p>
<p>把<code>zsh</code>设置为默认终端<code>chsh -s $(which zsh)</code></p>
<p>更多细节参考<a href="https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH" target="_blank" rel="external">Installing ZSH</a></p>
<p>先欣赏下<code>zsh</code>的效果。来自官网</p>
<p><img src="https://i.imgur.com/hLnYQUr.jpg" alt=""></p>
<p><img src="https://i.imgur.com/DHJp9Zy.jpg" alt=""></p>
<p><img src="https://i.imgur.com/EA7m7Ln.jpg" alt=""></p>
<h1 id="修改zsh主题"><a href="#修改zsh主题" class="headerlink" title="修改zsh主题"></a>修改zsh主题</h1><p><code>vi ~/.zshrc</code>，然后找到<code>ZSH_THEME</code>，默认的是<code>ZSH_THEME=robbyrussell</code>，就像我这样，因为我这里用的是深度终端，而且也修改了终端主题</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180605191149.png" alt=""></p>
<p>当然，你可以来这里看看，选一个自己喜欢的主题 <a href="https://github.com/robbyrussell/oh-my-zsh/wiki/themes" target="_blank" rel="external">Themes</a></p>
<p><img src="https://cloud.githubusercontent.com/assets/2618447/6316862/70f58fb6-ba03-11e4-82c9-c083bf9a6574.png" alt=""></p>
<p><code>agnoster</code>也很好看。</p>
<p>据说大神都用<code>random</code>，是真的吗？</p>
<h1 id="安装-fish"><a href="#安装-fish" class="headerlink" title="安装 fish"></a>安装 fish</h1><p>有句话这样说</p>
<blockquote>
<p>二逼青年用 bash，普通青年用 zsh，文艺青年用 <a href="http://fishshell.com/" target="_blank" rel="external">fish</a></p>
</blockquote>
<p>我最喜欢 <code>fish</code>的一点就是 <strong>根据历史输入自动补全</strong>，来看图，只要是历史有输入的，都会有记录有提示，对于一些很长的命令，简直超级爽，再也不用手动复制粘贴了。</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180605191928.png" alt=""></p>
<p>但是<code>fish</code>和<code>zsh</code>好像不能同时使用，但是有一个插件可以在<code>zsh</code>上达到和<code>fish</code>同样的效果。</p>
<p>地址在这里 <a href="https://github.com/zsh-users/zsh-autosuggestions" target="_blank" rel="external"><strong>zsh-autosuggestions</strong></a></p>
<p>首先下载下来</p>
<p><code>git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions</code></p>
<p>然后<code>vi ~/.zshrc</code>，添加<code>zsh-autosuggestions</code>到plugins中，<code>git</code>是默认就有的。然后新打开一个终端，就可以达到<code>fish</code>有的你是提示功能了。</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180605193558.png" alt=""></p>
<p>还可以安装语法高亮插件 <a href="https://github.com/zsh-users/zsh-syntax-highlighting" target="_blank" rel="external">zsh-syntax-highlighting</a>，安装方法和上面的一样，在plugins中添加<code>zsh-syntax-highlighting</code>即可。</p>
<p>这些是我目前发现的比较好用的插件和工具，大家有什么推荐的吗？</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十二篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;好看、好用  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180605191928.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="终端" scheme="https://zhangslob.github.io/categories/%E7%BB%88%E7%AB%AF/"/>
    
    
      <category term="zsh" scheme="https://zhangslob.github.io/tags/zsh/"/>
    
      <category term="linux" scheme="https://zhangslob.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>爬虫学到什么程度可以去找工作</title>
    <link href="https://zhangslob.github.io/2018/05/29/%E7%88%AC%E8%99%AB%E5%AD%A6%E5%88%B0%E4%BB%80%E4%B9%88%E7%A8%8B%E5%BA%A6%E5%8F%AF%E4%BB%A5%E5%8E%BB%E6%89%BE%E5%B7%A5%E4%BD%9C/"/>
    <id>https://zhangslob.github.io/2018/05/29/爬虫学到什么程度可以去找工作/</id>
    <published>2018-05-29T14:52:52.000Z</published>
    <updated>2018-05-29T16:09:07.909Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十一篇原创文章
</code></pre><p>分享下我的经验与教训  (๑• . •๑)</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527615838846&amp;di=6927100e3cb49201774aa07736031e9b&amp;imgtype=0&amp;src=http%3A%2F%2Fwww.btestingsky.com%2Ffiles%2Fcourse%2F2015%2F04-14%2F16211177d887256747.gif%3F4.2.0" alt=""></p>
<a id="more"></a>
<p>最近很多朋友问我，我在自学爬虫，学到什么程度可以去找工作呢？</p>
<p>这篇文章会说说我自己的心得体验，关于爬虫、关于工作，仅供参考。</p>
<h1 id="学到哪种程度"><a href="#学到哪种程度" class="headerlink" title="学到哪种程度"></a>学到哪种程度</h1><p>暂且把目标定位初级爬虫工程师，简单列一下吧：</p>
<p>（必要部分）</p>
<ol>
<li>语言选择：一般是了解Python、Java、Golang之一</li>
<li>熟悉多线程编程、网络编程、HTTP协议相关</li>
<li>开发过完整爬虫项目（最好有全站爬虫经验，这个下面会说到）</li>
<li>反爬相关，cookie、ip池、验证码等等</li>
<li>熟练使用分布式</li>
</ol>
<p>（非必要，建议）</p>
<ol>
<li>了解消息队列，如RabbitMQ、Kafka、Redis等</li>
<li>具有数据挖掘、自然语言处理、信息检索、机器学习经验</li>
<li>熟悉APP数据采集、中间人代理</li>
<li>大数据处理（Hive/MR/Spark/Storm）</li>
<li>数据库Mysql，redis，mongdb</li>
<li>熟悉Git操作、linux环境开发</li>
<li>读懂js代码，这个真的很重要</li>
</ol>
<h1 id="如何提升"><a href="#如何提升" class="headerlink" title="如何提升"></a>如何提升</h1><p>随便看看知乎上的教程就可以入门了，就Python而言，会requests当然是不够的，还需要了解scrapy和pyspider这两个框架，scrapy_redis也是需要理解原理的。</p>
<p>分布式如何搭建、如何解决其中遇到内存、速度问题。</p>
<p>参考 <a href="https://mp.weixin.qq.com/s?__biz=MzIwNjUxMTQyMA==&amp;mid=2247484093&amp;idx=1&amp;sn=f6d3d91af46830816c1ad30221504630&amp;chksm=9721ceeea05647f86376f66d75cff028f5c03c9930dbb1ca14bb3d290437be2509a4420d0f7a#rd" target="_blank" rel="external">scrapy-redis 和 scrapy 有什么区别？</a></p>
<p><img src="https://i.imgur.com/1uic8Qk.jpg" alt=""></p>
<h1 id="什么叫全站爬取"><a href="#什么叫全站爬取" class="headerlink" title="什么叫全站爬取"></a>什么叫全站爬取</h1><p>最简单的拿拉钩来举例，搜索关键词，有30页，不要以为把这30页爬完就是全站爬取了，你应该想方法把所有数据全部爬下来。</p>
<p>什么办法，通过筛选缩小范围，慢慢来就OK了。</p>
<p>同时，每个职位还会有推荐职位，再写一个采集推荐的爬虫。</p>
<p><img src="https://i.imgur.com/MuvjEAt.png" alt=""></p>
<p>这个过程需要注意的是如何去重，Mongo可以、redis也可以 </p>
<p>参考 <a href="https://mp.weixin.qq.com/s?__biz=MzIwNjUxMTQyMA==&amp;mid=2247484074&amp;idx=1&amp;sn=c5d2e89ca4f30024ed213f07cd148cb2&amp;chksm=9721cef9a05647ef3c3ba3c5344de607af087d3688dbf089dd2a45519894469fe10bbc06a277#rd" target="_blank" rel="external">Scrapy中如何提高数据的插入速度</a></p>
<h1 id="实际项目经验"><a href="#实际项目经验" class="headerlink" title="实际项目经验"></a>实际项目经验</h1><p>这个面试中肯定会被人问道，如：</p>
<ol>
<li>你爬过哪些网站</li>
<li>日均最大采集量是多少</li>
<li>你遇到哪些棘手问题，如何解决</li>
<li>等等</li>
</ol>
<p>那么怎么找项目呢？比如我要爬微博数据，去Github中搜索下，项目还算少吗？</p>
<p><img src="https://i.imgur.com/MlMcavz.png" alt=""></p>
<h1 id="语言选择"><a href="#语言选择" class="headerlink" title="语言选择"></a>语言选择</h1><p>我自己建议是Python、Java、Golang最好都了解，Java爬虫的也很多，但是网上教程几乎都是Python的，悲哀。</p>
<p>最后说下Golang，Golang真的很牛逼，说个数字，Golang可以每分钟下载网页数量 2W ，Python可以吗~~</p>
<p><img src="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=3503054989,264376367&amp;fm=11&amp;gp=0.jpg" alt=""></p>
<p>宣传下自己的刷题项目 <a href="https://github.com/zhangslob/Leetcode-Solutions" target="_blank" rel="external">Leetcode Solutions By All Language</a></p>
<h1 id="关于反爬"><a href="#关于反爬" class="headerlink" title="关于反爬"></a>关于反爬</h1><p>常见的 UA、Refer等需要了解是什么东西，有些验证的ID如何产生的，是否必要；关于IP池这块我不了解，不多说，需要注意的是如何设计拉黑机制；模拟登陆也是必要的，<a href="https://github.com/xchaoinfo/fuck-login" target="_blank" rel="external">fuck-login</a> 可以研究下代码，或者提PR。</p>
<p><img src="https://i.imgur.com/vhXq9Lw.png" alt=""></p>
<blockquote>
<p>模拟登陆其实就是一步步的请求，保存cookie会话</p>
</blockquote>
<h1 id="如何判断能力足够"><a href="#如何判断能力足够" class="headerlink" title="如何判断能力足够"></a>如何判断能力足够</h1><p>很简单，给个任务，爬取知乎上所有问题。</p>
<p>你会如何思考并设计这个项目？</p>
<p>欢迎留言指出</p>
<hr>
<blockquote>
<p>以上仅为个人看法，若有不足之处请指出。希望可以帮助你</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十一篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;分享下我的经验与教训  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://timgsa.baidu.com/timg?image&amp;amp;quality=80&amp;amp;size=b9999_10000&amp;amp;sec=1527615838846&amp;amp;di=6927100e3cb49201774aa07736031e9b&amp;amp;imgtype=0&amp;amp;src=http%3A%2F%2Fwww.btestingsky.com%2Ffiles%2Fcourse%2F2015%2F04-14%2F16211177d887256747.gif%3F4.2.0&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>你写过哪些让你睡不好觉的BUG</title>
    <link href="https://zhangslob.github.io/2018/05/28/%E4%BD%A0%E5%86%99%E8%BF%87%E5%93%AA%E4%BA%9B%E8%AE%A9%E4%BD%A0%E7%9D%A1%E4%B8%8D%E5%A5%BD%E8%A7%89%E7%9A%84BUG/"/>
    <id>https://zhangslob.github.io/2018/05/28/你写过哪些让你睡不好觉的BUG/</id>
    <published>2018-05-28T15:38:35.000Z</published>
    <updated>2018-05-29T14:54:00.475Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十篇原创文章
</code></pre><p>你写过什么有趣的BUG？  (๑• . •๑)</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527532149198&amp;di=dcd173ae2aab83b73a2e6bfd043a8ca9&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20171024%2F8d81ef9e1a014084af9aa0a4e068f75b.jpeg" alt=""></p>
<a id="more"></a>
<p>今天，聊聊 BUG。</p>
<p>今天下午发现程序中一个BUG，紧急修复之后重新上线，debug上测试没毛病，OK上正式环境。build完之后，程序一直有问题，没法读数据，头疼啊，自己看的眼睛都要瞎了，找不到原因。</p>
<p>增加更多日志，给出错的地方每一条都打印出日志来，看看到底是哪里出了问题。改完，上debug，好的没毛病，上正式环境，根据日志我大概判断出是那里的问题了，改，线下测试，debug测试，都没问题，再上正式版，还是不行。</p>
<p>这个时候已经精疲力竭了，想砸电脑！！！</p>
<p>为什么debug环境可以，正式环境不行啊？？</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527532671810&amp;di=9d88a0db0b7cb537c79da3df79af9c3f&amp;imgtype=0&amp;src=http%3A%2F%2Fimage.woshipm.com%2Fwp-files%2F2015%2F08%2Fbug2.png" alt=""></p>
<p>然后程序就跑起来了，是的，就跑起来了。下班，回家。（已经快10点了）</p>
<p>回到家，洗完澡，写完这篇文章，再去检查日志，so far so good！！开心~</p>
<p>现在我再仔细想了想，可能是这样：线上服务器和数据库压力比较大，程序子线程没有跑起来、或者数据库没建索引、查询时间过久（明天去验证下，因为之前一直没遇到类似问题）</p>
<p>不管了，我要睡觉了。</p>
<p>来讨论下，你写过什么让你睡不好觉的BUG？</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527532888936&amp;di=02b78519760eb95f70324934244548f2&amp;imgtype=0&amp;src=http%3A%2F%2Ftop.jobbole.com%2Fwp-content%2Fuploads%2Fsites%2F8%2F2014%2F09%2F148c6b0cefed4e594acd40957dda2c54.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;你写过什么有趣的BUG？  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://timgsa.baidu.com/timg?image&amp;amp;quality=80&amp;amp;size=b9999_10000&amp;amp;sec=1527532149198&amp;amp;di=dcd173ae2aab83b73a2e6bfd043a8ca9&amp;amp;imgtype=0&amp;amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20171024%2F8d81ef9e1a014084af9aa0a4e068f75b.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="日常" scheme="https://zhangslob.github.io/categories/%E6%97%A5%E5%B8%B8/"/>
    
    
      <category term="BUG" scheme="https://zhangslob.github.io/tags/BUG/"/>
    
  </entry>
  
  <entry>
    <title>git大法好，push需谨慎</title>
    <link href="https://zhangslob.github.io/2018/05/26/git%E5%A4%A7%E6%B3%95%E5%A5%BD%EF%BC%8Cpush%E9%9C%80%E8%B0%A8%E6%85%8E/"/>
    <id>https://zhangslob.github.io/2018/05/26/git大法好，push需谨慎/</id>
    <published>2018-05-26T07:38:28.000Z</published>
    <updated>2018-05-26T08:13:38.659Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十九篇原创文章
</code></pre><p>注意自己的账号安全  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/lptSYQU.jpg" alt=""></p>
<a id="more"></a>
<blockquote>
<p>在每次<code>git push</code>前，请检查你的提交文件</p>
</blockquote>
<p>故事是这样来的。（我又开始讲故事了）</p>
<p>前几天在 Github上找一些资料，碰巧看到一个合适的，就把他 clone 下来，准备在本地跑着试试看效果，但是在运行的时候却发现提示错误，根绝错误提示原因我发现是缺少了一个名为<code>config.py</code>的文件。</p>
<p>经验告诉我，这应该是一个写有相关配置的文件。现在缺少了这个文件，整个程序就没法运行，自己写的话又不知道格式什么的。</p>
<p>那我该怎么办？</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527331404813&amp;di=84868955d0e2240e0afc9c5053259864&amp;imgtype=0&amp;src=http%3A%2F%2Fimg.ishuo.cn%2Fdoc%2F1703%2F861-1F31G64602-51.jpg" alt=""></p>
<p>最后我还是找到了，在Github上。我去该项目上看到作者提交了很多次的<code>commit</code>，从历史的提交中我找到了相关信息。这是一个包含有作者相关数据库的文件，我已经通知作者，让他去删除此项目。</p>
<p>看下图，每个开源项目都会显示所有的<code>commits</code>，每次提交都会把git工作目录下所有文件提交（当然你可以指定具体的文件，我习惯<code>git add .</code>）。即使你下今天把密码删除了，但是你昨天提交的密码还是会保存到<code>commits</code>中，别人还是可以找到。</p>
<p>例如你现在看到的项目 <a href="https://github.com/zhangslob/Leetcode-Solutions" target="_blank" rel="external">Leetcode-Solutions</a> ，你可以从<code>commit</code>中进入，查看到历史<code>contributors</code>的每一次提交的完整文件， 如：<a href="https://github.com/zhangslob/Leetcode-Solutions/tree/f237fe70338eeb1e9e7c950423b254b7495ab3c7" target="_blank" rel="external">很久之前的提交</a></p>
<p><img src="https://i.imgur.com/NRDG7XU.png" alt=""></p>
<p><img src="https://i.imgur.com/8ErZTIZ.png" alt=""></p>
<p>所以看到这里，你就有必要想想自己有没有把任何个人隐私数据提交到 Github 上，如果有，建议还是删除项目吧。</p>
<p>当然，这有一个前提，就是你的项目是公开的（Public），如果是私有的（Private），就不用考虑了。</p>
<p><img src="https://i.imgur.com/DHFLCfn.png" alt=""></p>
<p>创建私有项目是收费的，一般适合公司和组织。</p>
<p>最后首尾呼应： git大法好，push需谨慎</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十九篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意自己的账号安全  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/lptSYQU.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Git" scheme="https://zhangslob.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://zhangslob.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>Python最假的库：Faker</title>
    <link href="https://zhangslob.github.io/2018/05/22/Python%E6%9C%80%E5%81%87%E7%9A%84%E5%BA%93%EF%BC%9AFaker/"/>
    <id>https://zhangslob.github.io/2018/05/22/Python最假的库：Faker/</id>
    <published>2018-05-22T13:14:35.000Z</published>
    <updated>2018-05-22T13:57:47.151Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十八篇原创文章
</code></pre><p>好假啊  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/fJSZZli.jpg" alt=""></p>
<a id="more"></a>
<blockquote>
<p>先申明下，这里说的Faker和LOL的大魔王没有任何关系，只是恰好重名而已。</p>
</blockquote>
<h1 id="故事由来"><a href="#故事由来" class="headerlink" title="故事由来"></a>故事由来</h1><p>最近做一个项目时需要随机生成人的名字，百度之后，我是这样写的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_first_name</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""百家姓中选择一个"""</span></div><div class="line">    name = [<span class="string">'赵'</span>, <span class="string">'钱'</span>, <span class="string">'孙'</span>, <span class="string">'李'</span>, <span class="string">'周'</span>, <span class="string">'吴'</span>, <span class="string">'郑'</span>, <span class="string">'王'</span>, <span class="string">'冯'</span>, <span class="string">'陈'</span>, <span class="string">'褚'</span>, <span class="string">'卫'</span>, <span class="string">'蒋'</span>, <span class="string">'沈'</span>, <span class="string">'韩'</span>, <span class="string">'杨'</span>, <span class="string">'朱'</span>, <span class="string">'秦'</span>, <span class="string">'尤'</span>, <span class="string">'许'</span>, <span class="string">'何'</span>, <span class="string">'吕'</span>, <span class="string">'施'</span>, <span class="string">'张'</span>, <span class="string">'孔'</span>, <span class="string">'曹'</span>, <span class="string">'严'</span>, <span class="string">'华'</span>, <span class="string">'金'</span>, <span class="string">'魏'</span>, <span class="string">'陶'</span>, <span class="string">'姜'</span>, <span class="string">'戚'</span>, <span class="string">'谢'</span>, <span class="string">'邹'</span>, <span class="string">'喻'</span>, <span class="string">'柏'</span>, <span class="string">'水'</span>, <span class="string">'窦'</span>, <span class="string">'章'</span>, <span class="string">'云'</span>, <span class="string">'苏'</span>, <span class="string">'潘'</span>, <span class="string">'葛'</span>, <span class="string">'奚'</span>, <span class="string">'范'</span>, <span class="string">'彭'</span>, <span class="string">'郎'</span>, <span class="string">'鲁'</span>, <span class="string">'韦'</span>, <span class="string">'昌'</span>, <span class="string">'马'</span>, <span class="string">'苗'</span>, <span class="string">'凤'</span>, <span class="string">'花'</span>, <span class="string">'方'</span>, <span class="string">'俞'</span>, <span class="string">'任'</span>, <span class="string">'袁'</span>, <span class="string">'柳'</span>]</div><div class="line">    <span class="keyword">return</span> random.choice(name)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_last_name</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""生成随机汉语"""</span></div><div class="line">    head = random.randint(<span class="number">0xb0</span>, <span class="number">0xf7</span>)</div><div class="line">    body = random.randint(<span class="number">0xa1</span>, <span class="number">0xf9</span>)   <span class="comment"># 在head区号为55的那一块最后5个汉字是乱码,为了方便缩减下范围</span></div><div class="line">    val = f<span class="string">'&#123;head:x&#125;&#123;body:x&#125;'</span></div><div class="line">    str_ = bytes.fromhex(val).decode(<span class="string">'gb2312'</span>)</div><div class="line">    <span class="keyword">return</span> str_</div><div class="line"></div><div class="line">name = random_first_name() + random_last_name()</div></pre></td></tr></table></figure>
<p>前辈在review的时候说怎么这么复杂，Python中有一个专门生成各类假数据的库：Faker，你去了解下。</p>
<h1 id="Faker"><a href="#Faker" class="headerlink" title="Faker"></a>Faker</h1><p>项目地址：<a href="https://github.com/joke2k/faker" target="_blank" rel="external">faker</a></p>
<p>安装：<code>pip install Faker</code></p>
<p>中文生成假数据：<a href="https://faker.readthedocs.io/en/master/locales/zh_CN.html" target="_blank" rel="external">Language zh_CN</a></p>
<p>那么Faker能生成那些假数据了？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> faker <span class="keyword">import</span> Faker</div><div class="line"></div><div class="line">fake = Faker(locale=<span class="string">'zh_CN'</span>)</div><div class="line"><span class="comment"># 初始化</span></div></pre></td></tr></table></figure>
<h2 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">fake.street_name()</div><div class="line"><span class="comment"># '广州街</span></div><div class="line"></div><div class="line">fake.city_suffix()</div><div class="line"><span class="comment"># '县'</span></div><div class="line"></div><div class="line">fake.street_address()</div><div class="line"><span class="comment"># '香港路B座'</span></div><div class="line"></div><div class="line">fake.longitude()</div><div class="line"><span class="comment"># -98.702031</span></div><div class="line"></div><div class="line">fake.district()</div><div class="line"><span class="comment"># '璧山'</span></div></pre></td></tr></table></figure>
<h2 id="汽车"><a href="#汽车" class="headerlink" title="汽车"></a>汽车</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">fake.license_plate()</div><div class="line"><span class="comment"># HZL 767</span></div></pre></td></tr></table></figure>
<h2 id="银行"><a href="#银行" class="headerlink" title="银行"></a>银行</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">fake.bban()</div><div class="line"><span class="comment"># 'KLUX5928618542924'</span></div><div class="line"></div><div class="line">fake.bank_country()</div><div class="line"><span class="comment"># 'GB'</span></div><div class="line"></div><div class="line">fake.iban()</div><div class="line"><span class="comment"># 'GB04BPNH0448315286040'</span></div></pre></td></tr></table></figure>
<h2 id="条形码"><a href="#条形码" class="headerlink" title="条形码"></a>条形码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">fake.ean(length=<span class="number">13</span>)</div><div class="line"><span class="comment"># '0994331656275'</span></div><div class="line"></div><div class="line">fake.ean8()</div><div class="line"><span class="comment"># '51309350'</span></div><div class="line"></div><div class="line">fake.ean13()</div><div class="line"><span class="comment"># '8336323543385'</span></div></pre></td></tr></table></figure>
<h2 id="公司"><a href="#公司" class="headerlink" title="公司"></a>公司</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">fake.company_prefix()</div><div class="line"><span class="comment"># '鸿睿思博'</span></div><div class="line"></div><div class="line">fake.bs()</div><div class="line"><span class="comment"># 'embrace strategic schemas'</span></div><div class="line"></div><div class="line">fake.company_suffix()</div><div class="line"><span class="comment"># '科技有限公司'</span></div><div class="line"></div><div class="line">fake.company()</div><div class="line"><span class="comment"># '昂歌信息网络有限公司'</span></div></pre></td></tr></table></figure>
<h2 id="信用卡"><a href="#信用卡" class="headerlink" title="信用卡"></a>信用卡</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">fake.credit_card_security_code(card_type=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># '360'</span></div><div class="line"></div><div class="line">fake.credit_card_full(card_type=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># 'Diners Club / Carte Blanche\n林 莘\n30311852484679 10/19\nCVC: 388\n'</span></div><div class="line"></div><div class="line">fake.credit_card_number(card_type=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># '30240280288941'</span></div><div class="line"></div><div class="line">fake.credit_card_expire(start=<span class="string">"now"</span>, end=<span class="string">"+10y"</span>, date_format=<span class="string">"%m/%y"</span>)</div><div class="line"><span class="comment"># '11/26'</span></div><div class="line"></div><div class="line">fake.credit_card_provider(card_type=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># 'Maestro'</span></div></pre></td></tr></table></figure>
<h2 id="互联网"><a href="#互联网" class="headerlink" title="互联网"></a>互联网</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">fake.domain_word(*args, **kwargs)</div><div class="line"><span class="comment"># 'jin'</span></div><div class="line"></div><div class="line">fake.company_email(*args, **kwargs)</div><div class="line"><span class="comment"># 'zoulei@hou.com'</span></div><div class="line"></div><div class="line">fake.free_email(*args, **kwargs)</div><div class="line"><span class="comment"># 'vxu@yahoo.com'</span></div><div class="line"></div><div class="line">fake.ipv4_private(network=<span class="keyword">False</span>, address_class=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># '10.202.214.57'</span></div><div class="line"></div><div class="line">fake.ascii_safe_email(*args, **kwargs)</div><div class="line"><span class="comment"># 'baiyan@example.net'</span></div><div class="line"></div><div class="line">fake.email(*args, **kwargs)</div><div class="line"><span class="comment"># 'minggao@gmail.com'</span></div><div class="line"></div><div class="line">fake.image_url(width=<span class="keyword">None</span>, height=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># 'https://www.lorempixel.com/817/102'</span></div><div class="line"></div><div class="line">fake.uri_page()</div><div class="line"><span class="comment"># 'category'</span></div><div class="line"></div><div class="line">fake.ipv4_network_class()</div><div class="line"><span class="comment"># 'c'</span></div></pre></td></tr></table></figure>
<h2 id="姓名"><a href="#姓名" class="headerlink" title="姓名"></a>姓名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">fake.first_name_female()</div><div class="line"><span class="comment"># '秀华'</span></div><div class="line"></div><div class="line">fake.name_male()</div><div class="line"><span class="comment"># '郏杰'</span></div><div class="line"></div><div class="line">fake.suffix_female()</div><div class="line"><span class="comment"># ''</span></div><div class="line"></div><div class="line">fake.first_name()</div><div class="line"><span class="comment"># '东'</span></div><div class="line"></div><div class="line">fake.prefix_female()</div><div class="line"><span class="comment"># ''</span></div><div class="line"></div><div class="line">fake.last_name_male()</div><div class="line"><span class="comment"># '扶'</span></div><div class="line"></div><div class="line">fake.last_name()</div><div class="line"><span class="comment"># '荣'</span></div><div class="line"></div><div class="line">fake.name_female()</div><div class="line"><span class="comment"># '曹红'</span></div><div class="line"></div><div class="line">fake.suffix_male()</div><div class="line"><span class="comment"># ''</span></div><div class="line"></div><div class="line">fake.last_name_female()</div><div class="line"><span class="comment"># '辛'</span></div><div class="line"></div><div class="line">fake.last_romanized_name()</div><div class="line"><span class="comment"># 'Zhang'</span></div><div class="line"></div><div class="line">fake.first_romanized_name()</div><div class="line"><span class="comment"># 'Min'</span></div><div class="line"></div><div class="line">fake.romanized_name()</div><div class="line"><span class="comment"># 'Xiuying Qiao'</span></div><div class="line"></div><div class="line">fake.name()</div><div class="line"><span class="comment"># '钟想'</span></div></pre></td></tr></table></figure>
<h2 id="电话"><a href="#电话" class="headerlink" title="电话"></a>电话</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">fake.phone_number()</div><div class="line"><span class="comment"># '18874465626'</span></div><div class="line"></div><div class="line">fake.msisdn()</div><div class="line"><span class="comment"># '8086764507444'</span></div><div class="line"></div><div class="line">fake.phonenumber_prefix()</div><div class="line"><span class="comment"># 155</span></div></pre></td></tr></table></figure>
<h2 id="user-agent"><a href="#user-agent" class="headerlink" title="user_agent"></a>user_agent</h2><p>这个大家应该很熟悉，常用的就是 <code>fake-useragent</code>这个库<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">fake.mac_platform_token()</div><div class="line"><span class="comment"># 'Macintosh; Intel Mac OS X 10_12_1'</span></div><div class="line"></div><div class="line">fake.firefox()</div><div class="line"><span class="comment"># ('Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_9_4; rv:1.9.4.20) '</span></div><div class="line"><span class="comment">#  'Gecko/2012-05-03 04:16:34 Firefox/3.6.10')</span></div><div class="line"></div><div class="line">fake.windows_platform_token()</div><div class="line"><span class="comment"># 'Windows 95'</span></div><div class="line"></div><div class="line">fake.safari()</div><div class="line"><span class="comment"># ('Mozilla/5.0 (iPod; U; CPU iPhone OS 3_1 like Mac OS X; sat-IN) '</span></div><div class="line"><span class="comment">#  'AppleWebKit/533.2.4 (KHTML, like Gecko) Version/3.0.5 Mobile/8B113 '</span></div><div class="line"><span class="comment">#  'Safari/6533.2.4')</span></div><div class="line"></div><div class="line">fake.chrome(version_from=<span class="number">13</span>, version_to=<span class="number">63</span>, build_from=<span class="number">800</span>, build_to=<span class="number">899</span>)</div><div class="line"><span class="comment"># ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5331 (KHTML, like Gecko) '</span></div><div class="line"><span class="comment">#  'Chrome/52.0.838.0 Safari/5331')</span></div><div class="line"></div><div class="line">fake.opera()</div><div class="line"><span class="comment"># 'Opera/8.83.(X11; Linux i686; ce-RU) Presto/2.9.169 Version/10.00'</span></div><div class="line"></div><div class="line">fake.mac_processor()</div><div class="line"><span class="comment"># 'Intel'</span></div><div class="line"></div><div class="line">fake.user_agent()</div><div class="line"><span class="comment"># ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_9 rv:3.0; pa-IN) '</span></div><div class="line"><span class="comment">#  'AppleWebKit/532.47.6 (KHTML, like Gecko) Version/4.0.1 Safari/532.47.6')</span></div><div class="line"></div><div class="line">fake.linux_platform_token()</div><div class="line"><span class="comment"># 'X11; Linux x86_64'</span></div><div class="line"></div><div class="line">fake.linux_processor()</div><div class="line"><span class="comment"># 'i686'</span></div><div class="line"></div><div class="line">fake.internet_explorer()</div><div class="line"><span class="comment"># 'Mozilla/5.0 (compatible; MSIE 5.0; Windows NT 5.01; Trident/3.1)'</span></div></pre></td></tr></table></figure></p>
<p>这里举例的都是中文的，当然也有其他语言的，小伙伴可以去官网看看。</p>
<p>最近在和小伙伴刷题，欢迎加入 <a href="https://github.com/zhangslob/Leetcode-Solutions" target="_blank" rel="external">Leetcode Solutions By All Language</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十八篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;好假啊  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/fJSZZli.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="https://zhangslob.github.io/categories/python/"/>
    
    
      <category term="Faker" scheme="https://zhangslob.github.io/tags/Faker/"/>
    
  </entry>
  
  <entry>
    <title>强大的异步爬虫 with aiohttp</title>
    <link href="https://zhangslob.github.io/2018/05/16/%E5%BC%BA%E5%A4%A7%E7%9A%84%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB-aiohttp/"/>
    <id>https://zhangslob.github.io/2018/05/16/强大的异步爬虫-aiohttp/</id>
    <published>2018-05-16T09:00:07.000Z</published>
    <updated>2018-05-16T13:39:40.499Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十七篇原创文章
</code></pre><p>异步了解下  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/gBlZ2Mq.jpg" alt=""></p>
<a id="more"></a>
<hr>
<p>看到现在网络上大多讲的都是requests、scrapy，却没有说到爬虫中的神器：<strong>aiohttp</strong></p>
<h1 id="aiohttp-介绍"><a href="#aiohttp-介绍" class="headerlink" title="aiohttp 介绍"></a>aiohttp 介绍</h1><p>aiohttp是什么，官网上有这样一句话介绍：<code>Async HTTP client/server for asyncio and Python</code>，翻译过来就是 <code>asyncio和Python的异步HTTP客户端/服务器</code></p>
<p>主要特点是：</p>
<ol>
<li>支持客户端和HTTP服务器。 </li>
<li>无需使用Callback Hell即可支持Server WebSockets和Client WebSockets。 </li>
<li>Web服务器具有中间件，信号和可插拔路由。</li>
</ol>
<p>emmmm，好吧，还是来看代码吧</p>
<p>Client example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> aiohttp</div><div class="line"><span class="keyword">import</span> asyncio</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(session, url)</span>:</span></div><div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> response:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">await</span> response.text()</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</div><div class="line">        html = <span class="keyword">await</span> fetch(session, <span class="string">'http://httpbin.org/headers'</span>)</div><div class="line">        print(html)</div><div class="line"></div><div class="line">loop = asyncio.get_event_loop()</div><div class="line">loop.run_until_complete(main())</div></pre></td></tr></table></figure>
<p>output:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">"headers"</span>:&#123;<span class="string">"Accept"</span>:<span class="string">"*/*"</span>,<span class="string">"Accept-Encoding"</span>:<span class="string">"gzip, deflate"</span>,<span class="string">"Connection"</span>:<span class="string">"close"</span>,<span class="string">"Host"</span>:<span class="string">"httpbin.org"</span>,<span class="string">"User-Agent"</span>:<span class="string">"Python/3.6 aiohttp/3.2.1"</span>&#125;&#125;</div></pre></td></tr></table></figure>
<p>Server example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> aiohttp <span class="keyword">import</span> web</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">handle</span><span class="params">(request)</span>:</span></div><div class="line">    name = request.match_info.get(<span class="string">'name'</span>, <span class="string">"Anonymous"</span>)</div><div class="line">    text = <span class="string">"Hello, "</span> + name</div><div class="line">    <span class="keyword">return</span> web.Response(text=text)</div><div class="line"></div><div class="line">app = web.Application()</div><div class="line">app.add_routes([web.get(<span class="string">'/'</span>, handle),</div><div class="line">                web.get(<span class="string">'/&#123;name&#125;'</span>, handle)])</div><div class="line"></div><div class="line">web.run_app(app)</div></pre></td></tr></table></figure>
<p>output:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">======== Running on http://0.0.0.0:8080 ========</div><div class="line">(Press CTRL+C to quit)</div></pre></td></tr></table></figure>
<h1 id="aiohttp-与-requests"><a href="#aiohttp-与-requests" class="headerlink" title="aiohttp 与 requests"></a>aiohttp 与 requests</h1><p>去翻一下官方文档 <a href="https://aiohttp.readthedocs.io/en/stable/client_quickstart.html#" target="_blank" rel="external">Client Quickstart</a>，让我感觉非常熟悉，很多用法和requests相似。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</div><div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">'http://httpbin.org/get'</span>) <span class="keyword">as</span> resp:</div><div class="line">        print(resp.status)</div><div class="line">        print(<span class="keyword">await</span> resp.text())</div></pre></td></tr></table></figure>
<p>首先，官方推荐使用<a href="https://aiohttp.readthedocs.io/en/stable/client_reference.html#aiohttp.ClientSession" target="_blank" rel="external">ClientSession</a>来管理会话，这不就是<code>requests</code>中的<code>session</code>吗？用法也类似，使用<code>session.get()</code>去发送<code>get</code>请求，返回的<code>resp</code>中就有我们所需要的数据了，用法也和<code>requests</code>一样，<code>text（）</code>文本，<code>.json()</code>直接打印返回的<code>json</code>数据，<code>headers</code>什么的也一样，更多内容参考官方文档<a href="https://aiohttp.readthedocs.io/en/stable/client_reference.html#response-object" target="_blank" rel="external">Response object</a></p>
<p>既然已经有<code>requests</code>了，那为什么还要说<code>aiohttp</code>了？重点来了，<code>aiohttp</code>是异步的。在python3.5中，加入了<code>asyncio/await</code> 关键字，使得回调的写法更加直观和人性化。而<code>aiohttp</code>是一个提供异步web服务的库，<code>asyncio</code>可以实现单线程并发IO操作。</p>
<p><code>requests</code>写爬虫是同步的，是等待网页下载好才会执行下面的解析、入库操作，如果在下载网页时间太长会导致阻塞，使用<code>multiprocessing</code>或者 <code>threading</code>加速爬虫也是一种方法。</p>
<p>我们现在使用的<code>aiohttp</code>是异步的，简单来说，就是不需要等待，你尽管去下载网页就好了，我不用傻傻的等待你完成才进行下一步，我还有别的活要干。这样就极大的提高了下载网页的效率。</p>
<p>另外，<code>Scrapy</code>也是异步的，是基于Twisted事件驱动的。在任何情况下，都不要写阻塞的代码。阻塞的代码包括：</p>
<ol>
<li>访问文件、数据库或者Web</li>
<li>产生新的进程并需要处理新进程的输出，如运行shell命令</li>
<li>执行系统层次操作的代码，如等待系统队列</li>
</ol>
<h1 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h1><p>这里是使用<code>aiohttp</code>的一个爬虫实例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> asyncio</div><div class="line"></div><div class="line"><span class="keyword">import</span> aiohttp</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">AsnycGrab</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, url_list, max_threads)</span>:</span></div><div class="line"></div><div class="line">        self.urls = url_list</div><div class="line">        self.results = &#123;&#125;</div><div class="line">        self.max_threads = max_threads</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__parse_results</span><span class="params">(self, url, html)</span>:</span></div><div class="line"></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</div><div class="line">            title = soup.find(<span class="string">'title'</span>).get_text()</div><div class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">            <span class="keyword">raise</span> e</div><div class="line"></div><div class="line">        <span class="keyword">if</span> title:</div><div class="line">            self.results[url] = title</div><div class="line"></div><div class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_body</span><span class="params">(self, url)</span>:</span></div><div class="line">        <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</div><div class="line">            <span class="keyword">async</span> <span class="keyword">with</span> session.get(url, timeout=<span class="number">30</span>) <span class="keyword">as</span> response:</div><div class="line">                <span class="keyword">assert</span> response.status == <span class="number">200</span></div><div class="line">                html = <span class="keyword">await</span> response.read()</div><div class="line">                <span class="keyword">return</span> response.url, html</div><div class="line"></div><div class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_results</span><span class="params">(self, url)</span>:</span></div><div class="line">        url, html = <span class="keyword">await</span> self.get_body(url)</div><div class="line">        self.__parse_results(url, html)</div><div class="line">        <span class="keyword">return</span> <span class="string">'Completed'</span></div><div class="line"></div><div class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">handle_tasks</span><span class="params">(self, task_id, work_queue)</span>:</span></div><div class="line">        <span class="keyword">while</span> <span class="keyword">not</span> work_queue.empty():</div><div class="line">            current_url = <span class="keyword">await</span> work_queue.get()</div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                task_status = <span class="keyword">await</span> self.get_results(current_url)</div><div class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">                logging.exception(<span class="string">'Error for &#123;&#125;'</span>.format(current_url), exc_info=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eventloop</span><span class="params">(self)</span>:</span></div><div class="line">        q = asyncio.Queue()</div><div class="line">        [q.put_nowait(url) <span class="keyword">for</span> url <span class="keyword">in</span> self.urls]</div><div class="line">        loop = asyncio.get_event_loop()</div><div class="line">        tasks = [self.handle_tasks(task_id, q, ) <span class="keyword">for</span> task_id <span class="keyword">in</span> range(self.max_threads)]</div><div class="line">        loop.run_until_complete(asyncio.wait(tasks))</div><div class="line">        loop.close()</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    async_example = AsnycGrab([<span class="string">'http://edmundmartin.com'</span>,</div><div class="line">               <span class="string">'https://www.udemy.com'</span>,</div><div class="line">               <span class="string">'https://github.com/'</span>,</div><div class="line">               <span class="string">'https://zhangslob.github.io/'</span>,</div><div class="line">               <span class="string">'https://www.zhihu.com/'</span>], <span class="number">5</span>)</div><div class="line">    async_example.eventloop()</div><div class="line">    print(async_example.results)</div></pre></td></tr></table></figure>
<p>需要注意的是，你需要时刻在你的代码中使用异步操作，你如果在代码中使用同步操作，爬虫并不会报错，但是速度可能会受影响。</p>
<h1 id="其他异步库"><a href="#其他异步库" class="headerlink" title="其他异步库"></a>其他异步库</h1><p>因为爬虫不仅仅只有下载这块，还会有操作数据库，这里提供两个异步库：<code>aioredis</code>、<code>motor</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> asyncio</div><div class="line"><span class="keyword">import</span> aioredis</div><div class="line"></div><div class="line">loop = asyncio.get_event_loop()</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">go</span><span class="params">()</span>:</span></div><div class="line">    conn = <span class="keyword">await</span> aioredis.create_connection(</div><div class="line">        <span class="string">'redis://localhost'</span>, loop=loop)</div><div class="line">    <span class="keyword">await</span> conn.execute(<span class="string">'set'</span>, <span class="string">'my-key'</span>, <span class="string">'value'</span>)</div><div class="line">    val = <span class="keyword">await</span> conn.execute(<span class="string">'get'</span>, <span class="string">'my-key'</span>)</div><div class="line">    print(val)</div><div class="line">    conn.close()</div><div class="line">    <span class="keyword">await</span> conn.wait_closed()</div><div class="line">loop.run_until_complete(go())</div><div class="line"><span class="comment"># will print 'value'</span></div></pre></td></tr></table></figure>
<p>文档：<a href="http://aioredis.readthedocs.io/en/v1.1.0/index.html" target="_blank" rel="external">aioredis</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> motor.motor_asyncio</div><div class="line"></div><div class="line">client = motor.motor_asyncio.AsyncIOMotorClient(<span class="string">'mongodb://localhost:27017'</span>)</div><div class="line"></div><div class="line">db = client[<span class="string">'test_database'</span>]</div><div class="line">collection = db[<span class="string">'test_collection'</span>]</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">do_insert</span><span class="params">()</span>:</span></div><div class="line">    document = &#123;<span class="string">'key'</span>: <span class="string">'value'</span>&#125;</div><div class="line">    result = <span class="keyword">await</span> db.test_collection.insert_one(document)</div><div class="line">    print(<span class="string">'result %s'</span> % repr(result.inserted_id))</div><div class="line">    </div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">do_find_one</span><span class="params">()</span>:</span></div><div class="line">    document = <span class="keyword">await</span> db.test_collection.find_one(&#123;<span class="string">'i'</span>: &#123;<span class="string">'$lt'</span>: <span class="number">1</span>&#125;&#125;)</div><div class="line">    pprint.pprint(document)</div></pre></td></tr></table></figure>
<p>文档：<a href="https://motor.readthedocs.io/en/stable/index.html" target="_blank" rel="external">motor</a></p>
<p><img src="https://motor.readthedocs.io/en/stable/_images/motor.png" alt=""></p>
<p>本文仅仅介绍了<code>aiohttp</code>作为<code>Client</code>的用法， 有兴趣的朋友可以去研究下作为<code>Server</code>的用法，同样很强大。</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十七篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;异步了解下  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/gBlZ2Mq.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="https://zhangslob.github.io/categories/Leetcode/"/>
    
    
      <category term="Leetcode" scheme="https://zhangslob.github.io/tags/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode Solutions（一） two-sum</title>
    <link href="https://zhangslob.github.io/2018/05/15/Leetcode%20Solutions%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://zhangslob.github.io/2018/05/15/Leetcode Solutions（一）/</id>
    <published>2018-05-15T10:22:26.000Z</published>
    <updated>2018-05-15T15:58:09.668Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十六篇原创文章
</code></pre><p>开始刷题咯  (๑• . •๑)</p>
<p><img src="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=3503054989,264376367&amp;fm=11&amp;gp=0.jpg" alt=""></p>
<a id="more"></a>
<p><a href="https://leetcode-cn.com/problems/two-sum/description/" target="_blank" rel="external">Two Sum</a></p>
<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>给定一个整数数组和一个目标值，找出数组中和为目标值的两个数。</p>
<p>你可以假设每个输入只对应一种答案，且同样的元素不能被重复利用。</p>
<p>示例:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">给定 nums = [<span class="number">2</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">15</span>], target = <span class="number">9</span></div><div class="line"></div><div class="line">因为 nums[<span class="number">0</span>] + nums[<span class="number">1</span>] = <span class="number">2</span> + <span class="number">7</span> = <span class="number">9</span></div><div class="line">所以返回 [<span class="number">0</span>, <span class="number">1</span>]</div></pre></td></tr></table></figure></p>
<h1 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h1><h2 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h2><p><code>a + b = target</code></p>
<p>也可以看成是</p>
<p><code>a = target - b</code></p>
<p>在map[整数]整数的序号中，可以查询到a的序号。这样就不用嵌套两个for循环了。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">twoSum</span><span class="params">(nums []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> []<span class="title">int</span></span> &#123;</div><div class="line">	m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">int</span>, <span class="built_in">len</span>(nums))</div><div class="line">	<span class="keyword">for</span> i, b := <span class="keyword">range</span> nums &#123;</div><div class="line">		<span class="keyword">if</span> j, ok := m[target-b]; ok &#123;</div><div class="line">			<span class="keyword">return</span> []<span class="keyword">int</span>&#123;j, i&#125;</div><div class="line">		&#125;</div><div class="line">		m[nums[i]] = i</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> <span class="literal">nil</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><ol>
<li>由于要找到符合题意的数组元素的下标，所以先要将原来的数组深拷贝一份，然后排序。</li>
<li>然后在排序后的数组中找两个数使它们相加为target。这个思路比较明显：使用两个指针，一个指向头，一个指向尾，两个指针向中间移动并检查两个指针指向的数的和是否为target。如果找到了这两个数，再将这两个数在原数组中的位置找出来就可以了。</li>
<li>要注意的一点是：在原来数组中找下标时，需要一个从头找，一个从尾找，要不无法通过。如这个例子：numbers=[0,1,2,0]; target=0。如果都从头开始找，就会有问题。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span><span class="params">(self, nums, target)</span>:</span></div><div class="line">        <span class="keyword">if</span> len(nums) &lt;= <span class="number">1</span>:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        d = dict()</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)):</div><div class="line">            <span class="keyword">if</span> nums[i] <span class="keyword">in</span> d:</div><div class="line">                <span class="keyword">return</span> [d[nums[i]], i]</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                d[target - nums[i]] = i</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十六篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;开始刷题咯  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=3503054989,264376367&amp;amp;fm=11&amp;amp;gp=0.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="https://zhangslob.github.io/categories/Leetcode/"/>
    
    
      <category term="Leetcode" scheme="https://zhangslob.github.io/tags/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title>告别win10，拥抱linux</title>
    <link href="https://zhangslob.github.io/2018/05/12/%E5%91%8A%E5%88%ABwin10%EF%BC%8C%E6%8B%A5%E6%8A%B1linux/"/>
    <id>https://zhangslob.github.io/2018/05/12/告别win10，拥抱linux/</id>
    <published>2018-05-12T05:49:33.000Z</published>
    <updated>2018-05-12T06:39:43.145Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十五篇原创文章
</code></pre><p>安装linux操作系统  (๑• . •๑)</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_Desktop_20180512132633.png" alt=""></p>
<a id="more"></a>
<h1 id="win10-升级"><a href="#win10-升级" class="headerlink" title="win10 升级"></a>win10 升级</h1><p>先问你一个问题，你讨厌win10升级系统吗？</p>
<p>我的回答：是，明明已经把自动更新关闭了，可是还是会有“易升”，win10易升一直卸载不掉。所以就想试试别的系统。</p>
<p>linux是最好的选择。黑苹果暂时不考虑。</p>
<p><img src="http://img.mp.itc.cn/upload/20170408/35c850c176b9447da3fbb3d303172f2a_th.jpg" alt=""></p>
<h1 id="喜欢linux的理由"><a href="#喜欢linux的理由" class="headerlink" title="喜欢linux的理由"></a>喜欢linux的理由</h1><p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_Desktop_20180512132633.png" alt=""></p>
<blockquote>
<p>深度桌面</p>
</blockquote>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_deepin-terminal_20180512133029.png" alt=""></p>
<blockquote>
<p>深度终端（配合zsh超赞的）</p>
</blockquote>
<p>除了颜值外，程序兼容性会更好，安装各种东西会很方便。作为一名程序员，熟悉linux下基本操作也是必要的。</p>
<blockquote>
<p>我自己试过，爬虫会跑的更快。 手动滑稽</p>
</blockquote>
<h1 id="选择linux哪个版本"><a href="#选择linux哪个版本" class="headerlink" title="选择linux哪个版本"></a>选择linux哪个版本</h1><p>目前我使用过deepin和ubuntu18，对于完全的小白来说，我推荐deepin也就是深度操作系统，深度商店收入的应用可以基本满足，ubuntu很多应用安装起来比较麻烦，如果你喜欢折腾，那就上手ubuntu吧。</p>
<p>如果你和我一样 喜欢xxx，那就试试deepin和ubuntu18共存。</p>
<p>我现在的开机界面（渣渣像素）</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20180512135314.jpg" alt=""></p>
<h1 id="如何安装linux"><a href="#如何安装linux" class="headerlink" title="如何安装linux"></a>如何安装linux</h1><h2 id="安装deepin"><a href="#安装deepin" class="headerlink" title="安装deepin"></a>安装deepin</h2><p>使用U盘安装</p>
<p>先去下载：</p>
<ol>
<li><a href="http://cdimage.deepin.com/releases/15.5/deepin-15.5-amd64.iso" target="_blank" rel="external">ISO文件</a></li>
<li><a href="http://cdimage.deepin.com/applications/deepin-boot-maker/windows/deepin-boot-maker.exe" target="_blank" rel="external">深度启动盘制作工具</a></li>
</ol>
<p>然后安装启动盘制作工具，然后选择刚才下载的ISO文件，下一步选择你的U盘，然后就开始安装了。</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180512135903.png" alt=""></p>
<p><img src="https://www.deepin.org/wp-content/uploads/2016/12/deepin-boot-maker-2-cn.png" alt=""><br><img src="https://www.deepin.org/wp-content/uploads/2016/12/deepin-boot-maker-3-cn.png" alt=""></p>
<p>下一步，重启电脑，一般情况下电脑默认是从硬盘启动，因此，在使用U盘安装系统之前，您需要先进入电脑的BIOS界面将U盘设置为第一启动项。</p>
<p>台式机一般为 Delete 键、笔记本一般为 F2  或 F10 或 F12 键，即可进入 BIOS 设置界面。</p>
<ol>
<li>将深度操作系统光盘插入电脑光驱中。</li>
<li>启动电脑，将光盘设置为第一启动项。</li>
<li>进入安装界面，选择需要安装的语言。</li>
</ol>
<p><img src="https://www.deepin.org/wp-content/uploads/2016/12/deepin-installer1.png" alt=""></p>
<p>如果还不会，这里有官方录制的视频哦 <a href="https://www.bilibili.com/video/av16993752/" target="_blank" rel="external">深度安装器+深度探索频道第七期+深度操作系统官方出品</a></p>
<p>还有一种更加简单的方式就是下载 <a href="http://cdimage.deepin.com/applications/deepin-boot-maker/windows/deepin-system-installer.exe" target="_blank" rel="external">深度系统安装器</a></p>
<p><img src="https://i.imgur.com/mpkCwJg.png" alt=""></p>
<p>然后就是傻瓜操作了，记得关闭下 <a href="http://www.yxswz.com/x64bug.html" target="_blank" rel="external">安全启动</a></p>
<blockquote>
<p>小歪并不推荐使用第二种方式安装，在笔记本上怎么都没有效果，在台式上一次成功。所以大家有U盘的尽量使用U盘吧</p>
</blockquote>
<h2 id="安装ubuntu"><a href="#安装ubuntu" class="headerlink" title="安装ubuntu"></a>安装ubuntu</h2><p>需要用到上面提到过的<a href="http://cdimage.deepin.com/applications/deepin-boot-maker/windows/deepin-boot-maker.exe" target="_blank" rel="external">深度启动盘制作工具</a>，然后去下载 <a href="https://www.ubuntu.com/download/desktop" target="_blank" rel="external">ISO文件</a>，然后就是和上面安装方法一样的，进行操作即可。</p>
<p>有没有很简单。</p>
<p><img src="https://i.imgur.com/u3gBHqc.png" alt=""></p>
<blockquote>
<p>我的ubuntu界面，用得少，所以没美化</p>
</blockquote>
<h1 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h1><p>我使用deepin有一个月了，写代码用deepin，家里的台式还是win7，因为deepin虽然有steam，但是吃鸡不支持在linux下运行。</p>
<p>deepin完全可以满足我的办公需求，Pycharm、sublime、typora、chrome、网易云音乐等等都有，用起来很舒服，至少现在是这样感觉。但是有时候deepin也会卡死。</p>
<p>强烈建议上手linux，可以学到很多命令行操作，安装deepin就好，到时候你的电脑会Windows与deepin共存，根据场景选择系统。</p>
<p>有时间写一篇deepin美化与安装应用相关的东西，看到这一定要点赞哦。</p>
<p><img src="https://i.imgur.com/xbmqUXs.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十五篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安装linux操作系统  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_Desktop_20180512132633.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="https://zhangslob.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="https://zhangslob.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>linux下安装python3.6</title>
    <link href="https://zhangslob.github.io/2018/05/11/linux%E4%B8%8B%E5%AE%89%E8%A3%85python3-6/"/>
    <id>https://zhangslob.github.io/2018/05/11/linux下安装python3-6/</id>
    <published>2018-05-11T14:26:54.000Z</published>
    <updated>2018-05-11T14:35:28.614Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十四篇原创文章
</code></pre><p>linux操作  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/lJ8ygSI.jpg" alt=""></p>
<a id="more"></a>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">sudo sed -i <span class="string">'s\archive.ubuntu.com\mirrors.aliyun.com\g'</span> /etc/apt/sources.list</div><div class="line">sudo apt-get update</div><div class="line"><span class="built_in">cd</span> /home/</div><div class="line">sudo apt-get install gcc  make zlib1g-dev -y</div><div class="line">sudo apt-get install  libbz2-dev libsqlite3-dev  libxml2-dev  libffi-dev libssl-dev -y</div><div class="line">sudo apt install wget -y</div><div class="line">wget http://mirrors.sohu.com/python/3.6.2/Python-3.6.2.tgz <span class="comment"># 可以换成你想要的版本</span></div><div class="line">tar -xvf Python-3.6.2.tgz</div><div class="line"><span class="built_in">cd</span> Python-3.6.2</div><div class="line">./configure --prefix=/home/usr/python36/</div><div class="line">sudo make</div><div class="line">sudo make install</div><div class="line"><span class="built_in">cd</span> ../usr/python36/bin/</div><div class="line">sudo mkdir -p ~/.pip/</div><div class="line">sudo cat &lt;&lt; EOF &gt; ~/.pip/pip.conf</div><div class="line">[global]</div><div class="line">trusted-host=mirrors.aliyun.com</div><div class="line">index-url=http://mirrors.aliyun.com/pypi/simple/</div><div class="line">EOF</div><div class="line"></div><div class="line">sudo apt-get install libmysqlclient-dev -y</div><div class="line">ln <span class="_">-s</span> /home/usr/python36/bin/pip3 /usr/bin/pip36</div><div class="line">ln <span class="_">-s</span> /home/usr/python36/bin/python3 /usr/bin/python36</div></pre></td></tr></table></figure>
<p>以后就可以使用 <code>pip36</code>  <code>python36</code>来进行操作。</p>
<blockquote>
<p>如果在命令行中输入<code>scrapy</code>提示没这个命令，可以试试<code>python36 -m scrapy</code></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十四篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;linux操作  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/lJ8ygSI.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="https://zhangslob.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="https://zhangslob.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>护眼神器了解下</title>
    <link href="https://zhangslob.github.io/2018/05/08/%E6%8A%A4%E7%9C%BC%E7%A5%9E%E5%99%A8%E4%BA%86%E8%A7%A3%E4%B8%8B/"/>
    <id>https://zhangslob.github.io/2018/05/08/护眼神器了解下/</id>
    <published>2018-05-08T14:05:24.000Z</published>
    <updated>2018-05-08T14:33:44.442Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十三篇原创文章
</code></pre><p>保护眼睛  (๑• . •๑)</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180508221045.png" alt=""></p>
<a id="more"></a>
<p>整天面对屏幕，护眼是必须的，下面推荐几款小歪使用过的软件。</p>
<h1 id="flux"><a href="#flux" class="headerlink" title="flux"></a>flux</h1><p>官网：<a href="https://justgetflux.com/" target="_blank" rel="external">https://justgetflux.com/</a></p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180508221449.png" alt=""></p>
<p>使用起来非常简单，是我之前非常喜欢的一款产品，会随着一天之内光线强弱改变屏幕的颜色。但是在linux上似乎不起作用，安装之后，屏幕颜色没有发生任何变化，于是我放弃了，选择另一款软件 ==</p>
<h1 id="redshift"><a href="#redshift" class="headerlink" title="redshift"></a>redshift</h1><p>网站：<a href="https://github.com/jonls/redshift" target="_blank" rel="external">https://github.com/jonls/redshift</a></p>
<p><img src="https://camo.githubusercontent.com/eb9522ffd5105488dcda49404e4c3107ffd88a1b/687474703a2f2f6a6f6e6c732e646b2f6173736574732f72656473686966742d69636f6e2d3235362e706e67" alt=""></p>
<p>Ubuntu下<code>sudo apt-get install redshift</code>就可以安装，打开方式是在命令行输入<code>redshift -v -t 4500:2500</code>，然后颜色就会变得非常舒服。</p>
<blockquote>
<p>如果在你的电脑上 redshift 有时不工作，检查是否开启了多个 redshift。</p>
</blockquote>
<h1 id="Safe-Eyes"><a href="#Safe-Eyes" class="headerlink" title="Safe Eyes"></a>Safe Eyes</h1><p>网站：<a href="http://slgobinath.github.io/SafeEyes/" target="_blank" rel="external">http://slgobinath.github.io/SafeEyes/</a></p>
<p><img src="https://slgobinath.github.io/SafeEyes/assets/screenshots/safeeyes_1.png" alt=""></p>
<p>这款应用会自动关闭屏幕，间隔一段时间会有休息，这个是否好好放松下自己的眼睛。</p>
<blockquote>
<p>这个好像只能安装在linux上</p>
</blockquote>
<p>大家还有什么推荐的呢？欢迎评论指出</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十三篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;保护眼睛  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180508221045.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="https://zhangslob.github.io/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="护眼" scheme="https://zhangslob.github.io/tags/%E6%8A%A4%E7%9C%BC/"/>
    
  </entry>
  
  <entry>
    <title>awesome_crawl(一)：腾讯新闻</title>
    <link href="https://zhangslob.github.io/2018/05/01/awesome-crawl-%E4%B8%80-%EF%BC%9A%E8%85%BE%E8%AE%AF%E6%96%B0%E9%97%BB/"/>
    <id>https://zhangslob.github.io/2018/05/01/awesome-crawl-一-：腾讯新闻/</id>
    <published>2018-05-01T13:52:11.000Z</published>
    <updated>2018-05-01T14:04:08.818Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十二篇原创文章
</code></pre><p>awesome  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/oDTELIM.png" alt=""></p>
<a id="more"></a>
<p>项目地址：<a href="https://github.com/zhangslob/awesome_crawl" target="_blank" rel="external">https://github.com/zhangslob/awesome_crawl</a></p>
<h1 id="awesome-crawl（优美的爬虫）"><a href="#awesome-crawl（优美的爬虫）" class="headerlink" title="awesome_crawl（优美的爬虫）"></a>awesome_crawl（优美的爬虫）</h1><h3 id="1、腾讯新闻的全站爬虫"><a href="#1、腾讯新闻的全站爬虫" class="headerlink" title="1、腾讯新闻的全站爬虫"></a><a href="https://github.com/zhangslob/awesome_crawl/tree/master/qq_news/qq_news" target="_blank" rel="external">1、腾讯新闻的全站爬虫</a></h3><p><strong>采集策略</strong></p>
<p>从<a href="http://www.qq.com/map/" target="_blank" rel="external">网站地图</a>出发，找出所有子分类，从每个子分类中再寻找详情页面的链接。</p>
<p>首先寻找每条新闻的ID，然后移动端采集具体内容。</p>
<p>再去找一些推荐新闻的接口，做一个“泛爬虫”。</p>
<p><strong>说明</strong></p>
<p>整套系统中分为两部分，一套是生产者，专门去采集qq新闻的链接，然后存放到redis中，一套是消费者，从redis中读取这些链接，解析详情数据。<br>所有配置文件都是爬虫中的<code>custom_settings</code>中，可以自定义。</p>
<p>如果需要设置代理，请在<code>middlewares.ProxyMiddleware</code>中设置。</p>
<p><strong>qq_list</strong>: 这个爬虫是生产者。运行之后，在你的redis服务器中会出现<code>qq_detail:start_urls</code>，即种子链接</p>
<p><strong>qq_detail</strong>: 这个爬虫是生消费者，运行之后会消费redis里面的数据，如下图：</p>
<p><img src="https://i.imgur.com/j81d8AP.png" alt=""></p>
<p>你可以自行添加更多爬虫去采集种子链接，如从<a href="http://www.qq.com/" target="_blank" rel="external">首页</a>进入匹配，从推荐入口：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line">url = <span class="string">"https://pacaio.match.qq.com/xw/recommend"</span></div><div class="line"></div><div class="line">querystring = &#123;<span class="string">"num"</span>:<span class="string">"10^"</span>,<span class="string">"callback"</span>:<span class="string">"__jp0"</span>&#125;</div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'accept-encoding'</span>: <span class="string">"gzip, deflate, br"</span>,</div><div class="line">    <span class="string">'accept-language'</span>: <span class="string">"zh-CN,zh;q=0.9,en;q=0.8"</span>,</div><div class="line">    <span class="string">'user-agent'</span>: <span class="string">"Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1"</span>,</div><div class="line">    <span class="string">'accept'</span>: <span class="string">"*/*"</span>,</div><div class="line">    <span class="string">'referer'</span>: <span class="string">"https://xw.qq.com/m/recommend/"</span>,</div><div class="line">    <span class="string">'authority'</span>: <span class="string">"pacaio.match.qq.com"</span>,</div><div class="line">    <span class="string">'cache-control'</span>: <span class="string">"no-cache"</span>,</div><div class="line">    &#125;</div><div class="line"></div><div class="line">response = requests.request(<span class="string">"GET"</span>, url, headers=headers, params=querystring)</div><div class="line"></div><div class="line">print(response.text)</div></pre></td></tr></table></figure>
<p>等等，你所需要做的仅仅是把这些抓到的种子链接塞到redis里面，也就是启用<code>qq_news.pipelines.RedisStartUrlsPipeline</code>这个中间件。</p>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol>
<li>增加更多新闻链接的匹配，从推荐接口处获得更多种子链接</li>
<li>增加“泛爬虫”，采集种子链接</li>
<li>数据库字段检验</li>
<li>redis中数据为空爬虫自动关闭（目前redis数据被消费完之后爬虫并不会自动关闭，如下图）<br><img src="https://i.imgur.com/Sk4GDMA.png" alt=""></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十二篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;awesome  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/oDTELIM.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="scrapy" scheme="https://zhangslob.github.io/categories/scrapy/"/>
    
    
      <category term="awesome_crawl" scheme="https://zhangslob.github.io/tags/awesome-crawl/"/>
    
      <category term="scrapy" scheme="https://zhangslob.github.io/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>scrapy-redis 和 scrapy 有什么区别？</title>
    <link href="https://zhangslob.github.io/2018/04/21/%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F/"/>
    <id>https://zhangslob.github.io/2018/04/21/有什么区别？/</id>
    <published>2018-04-21T10:03:14.000Z</published>
    <updated>2018-04-21T10:09:16.780Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十一篇原创文章
</code></pre><p>分布式爬虫  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/1uic8Qk.jpg" alt=""></p>
<a id="more"></a>
<p>最近在工作中一直使用 <code>redis</code> 来管理分发爬虫任务，让我对 <code>scrapy-redis</code> 有很深刻的理解，下面让我慢慢说来。</p>
<blockquote>
<p>在所有的问题开始之前，要先有一个前提：你使用 <code>Scrapy</code> 框架做开发</p>
</blockquote>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p><code>scrapy-redis</code> 与 <code>Scrapy</code>的关系就像电脑与固态硬盘一样，是电脑中的一个插件，能让电脑更快的运行。</p>
<p><code>Scrapy</code> 是一个爬虫框架，<code>scrapy-redis</code> 则是这个框架上可以选择的插件，它可以让爬虫跑的更快。</p>
<h1 id="为什么使用-scrapy-redis"><a href="#为什么使用-scrapy-redis" class="headerlink" title="为什么使用 scrapy-redis"></a>为什么使用 <code>scrapy-redis</code></h1><p>首先，在实际开发中，我们总会对爬虫速度表示不满，为啥这么慢，能不能跑快点。除了爬虫本身的优化，我们就要引入<code>分布式爬虫</code>的概念。</p>
<p>我自己对<code>分布式爬虫</code>的理解就是：<strong>多个爬虫执行同一个任务</strong></p>
<blockquote>
<p>这里说下，<code>Scrapy</code>本身是不支持分布式的，因为它的任务管理和去重全部是在机器内存中实现的。</p>
</blockquote>
<p>在 <code>Scrapy</code> 中最出名的分布式插件就是<code>scrapy-redis</code>了，<code>scrapy-redis</code>的作用就是让你的爬虫快、更快、超级快。</p>
<h1 id="scrapy-redis-如何工作"><a href="#scrapy-redis-如何工作" class="headerlink" title="scrapy-redis 如何工作"></a><code>scrapy-redis</code> 如何工作</h1><p>最简单的方式是使用<code>redis</code>替换机器内存，那么具体如何操作呢？非常简单，你只需要在 <code>settings.py</code> 中加上三代码，就能让你的爬虫变为分布式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></div><div class="line"></div><div class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></div><div class="line"></div><div class="line">REDIS_START_URLS_AS_SET = <span class="keyword">True</span></div></pre></td></tr></table></figure>
<p><code>SCHEDULER</code> 是任务分发与调度，把所有的爬虫开始的请求都放在redis里面，所有爬虫都去redis里面读取请求。<br><code>DUPEFILTER_CLASS</code> 是去重队列，负责所有请求的去重，<code>REDIS_START_URLS_AS_SET</code>指的是使用redis里面的set类型（简单完成去重），如果你没有设置，默认会选用list。</p>
<p>如果你现在运行你的爬虫，你可以在redis中看到出现了这两个key:</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">spider_name:</span>dupefilter</div><div class="line"><span class="symbol">spider_name:</span>requests</div></pre></td></tr></table></figure>
<p>格式是set，即不会有重复数据。前者就是redis的去重队列，对应<code>DUPEFILTER_CLASS</code>，后者是redis的请求调度，把里面的请求分发给爬虫，对应<code>SCHEDULER</code>。（里面的数据不会自动删除，如果你第二次跑，需要提前清空里面的数据）</p>
<h1 id="scrapy-redis-优点"><a href="#scrapy-redis-优点" class="headerlink" title="scrapy-redis 优点"></a><code>scrapy-redis</code> 优点</h1><h3 id="速度快"><a href="#速度快" class="headerlink" title="速度快"></a>速度快</h3><p><code>scrapy-redis</code> 使用redis这个速度非常快的非关系型（NoSQL）内存键值数据库，<strong>速度快</strong>是最重要原因（但是也会产生负面想过，下面会说到）。</p>
<p>为什么是<code>scrapy-redis</code>而不是<code>scrapy-mongo</code>呢，大家可以仔细想想。</p>
<h3 id="用法简单"><a href="#用法简单" class="headerlink" title="用法简单"></a>用法简单</h3><p>前人已经造好轮子了，<a href="https://github.com/rmax/scrapy-redis" target="_blank" rel="external">scrapy-redis</a>。<br>我们直接拿来用就好，而用法也像上面提到的在 <code>settings.py</code> 文件中配置。在文档中还有另一种用法，即<code>Feeding a Spider from Redis</code></p>
<ol>
<li>run the spider:<br><code>scrapy runspider myspider.py</code></li>
<li>push urls to redis:<br><code>redis-cli lpush myspider:start_urls http://google.com</code>（建议把<code>lpush</code>换为<code>zset</code>）</li>
</ol>
<p>其实这种用法就是先打开一个爬虫，他会一直在redis里面寻找key为 <code>myspider:start_urls</code>，如果存在，就提取里面的url。当然你也可以在爬虫中指定<code>redis_key</code>，默认的是爬虫的名字加上<code>:start_urls</code></p>
<h3 id="去重简单"><a href="#去重简单" class="headerlink" title="去重简单"></a>去重简单</h3><p>爬虫中去重是一件大事，使用了<code>scrapy-redis</code>后就很简单了。上面提到过使用redis的set类型就可以很容易达到这个目标了，即<code>REDIS_START_URLS_AS_SET = True</code>。</p>
<h1 id="scrapy-redis-缺点"><a href="#scrapy-redis-缺点" class="headerlink" title="scrapy-redis 缺点"></a><code>scrapy-redis</code> 缺点</h1><h3 id="内存问题"><a href="#内存问题" class="headerlink" title="内存问题"></a>内存问题</h3><p>为什么使用分布式爬虫，当然是因为会有很多链接需要跑，或者说会存放很多个<code>myspider:start_urls</code>到redis中，Redis是key-value数据库，面对key的内存搜索，优势明显，但是Redis吃的是纯内存，<code>myspider:start_urls</code>是一个有一个像<code>https://www.zhihu.com/people/cuishite</code>的链接，会占用大量的内存空间。之前就因为这个原因redis崩溃过无数次，那么如何优化？</p>
<p>网络上有的方法是 <a href="https://blog.csdn.net/bone_ace/article/details/53099042" target="_blank" rel="external"> scrapy_redis去重优化（已有7亿条数据），附Demo福利</a>，可以参考下。如果你有好的解决方法，欢迎私信告诉我。（保密原因就不介绍我们的处理方法了）</p>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p>这个其实不算做问题，只是官方文档上我觉得的小BUG，在这里 <a href="https://github.com/rmax/scrapy-redis#usage" target="_blank" rel="external">Usage</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Store scraped item in redis for post-processing.</span></div><div class="line">ITEM_PIPELINES = &#123;</div><div class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">300</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Pipeline是这样写的<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_process_item</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">    key = self.item_key(item, spider)</div><div class="line">    data = self.serialize(item)</div><div class="line">    self.server.rpush(key, data)</div><div class="line">    <span class="keyword">return</span> item</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">item_key</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">    <span class="string">"""Returns redis key based on given spider.</span></div><div class="line"></div><div class="line">    Override this function to use a different key depending on the item</div><div class="line">    and/or spider.</div><div class="line"></div><div class="line">    """</div><div class="line">    <span class="keyword">return</span> self.key % &#123;<span class="string">'spider'</span>: spider.name&#125;</div></pre></td></tr></table></figure></p>
<p>看不懂为什么要把数据储存在redis里面，这不又加大redis储存负担吗？对于新手来说真的不友好，或许可以考虑提一个pr。</p>
<h1 id="redis可视化工具"><a href="#redis可视化工具" class="headerlink" title="redis可视化工具"></a>redis可视化工具</h1><p>最后介绍两个redis可视化工具</p>
<ol>
<li><a href="https://github.com/uglide/RedisDesktopManager" target="_blank" rel="external">RedisDesktopManager</a> 比较出名的工具，但是经常会崩溃</li>
<li><a href="https://github.com/uniorder/kedis" target="_blank" rel="external">kedis</a> 国人开发的免费工具，这个界面还是可以的</li>
</ol>
<p><img src="https://camo.githubusercontent.com/de76115b295d30222fa0d6a1b79ffc9b31fb04e5/687474703a2f2f7777772e6b656861772e636f6d2f696d616765732f73637265656e73686f742e706e67" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十一篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;分布式爬虫  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/1uic8Qk.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="scrapy" scheme="https://zhangslob.github.io/categories/scrapy/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://zhangslob.github.io/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>来codewars与我一起玩耍吧</title>
    <link href="https://zhangslob.github.io/2018/04/12/%E6%9D%A5codewars%E4%B8%8E%E6%88%91%E4%B8%80%E8%B5%B7%E7%8E%A9%E8%80%8D%E5%90%A7/"/>
    <id>https://zhangslob.github.io/2018/04/12/来codewars与我一起玩耍吧/</id>
    <published>2018-04-12T13:25:13.000Z</published>
    <updated>2018-04-12T14:08:23.123Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十篇原创文章
</code></pre><p>并肩作战  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/tyYtQ02.jpg" alt=""></p>
<a id="more"></a>
<h1 id="先看一道题目"><a href="#先看一道题目" class="headerlink" title="先看一道题目"></a>先看一道题目</h1><p>如何使用代码表示“石头、剪刀、布”之间的关系。</p>
<blockquote>
<p>即：石头 &gt; 剪刀，剪刀 &gt; 布， 剪刀 &gt; 布</p>
</blockquote>
<p>当时我想了很多，构造一个字典，和数字对应，但是应该如何表示“大小”关系呢？想破脑袋都想不出来，最后看了答案，形如</p>
<p><code>dict = {&#39;a&#39;: &#39;b&#39;, &#39;b&#39;: &#39;c&#39;, &#39;c&#39;: &#39;a&#39;}</code></p>
<p>简直是妙啊！！！</p>
<p>原题在这里，<a href="https://www.codewars.com/kata/5672a98bdbdd995fad00000f" target="_blank" rel="external">Rock Paper Scissors!</a>，可以自己试试看。</p>
<p>我觉得很妙的解法</p>
<h1 id="CodeWars"><a href="#CodeWars" class="headerlink" title="CodeWars"></a>CodeWars</h1><p>这是CodeWars上的一题，我觉得挺有意思的。CodeWars其实和leetcode差不多，但是我更喜欢有这几点。</p>
<h2 id="界面"><a href="#界面" class="headerlink" title="界面"></a>界面</h2><p><img src="https://i.imgur.com/iJDJEyh.png" alt=""></p>
<p>看着挺舒服的，同时提供了测试代码。</p>
<h2 id="够简单"><a href="#够简单" class="headerlink" title="够简单"></a>够简单</h2><p>真的，CodeWars上有些题目真的很简单，适合我这种新手，哈哈，比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Complete the solution so that it reverses the string value passed into it.</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># solution('world') # returns 'dlrow'</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(string)</span>:</span></div><div class="line">    <span class="keyword">return</span> string[::<span class="number">-1</span>]</div></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/76PQr2I.png" alt=""></p>
<p>还可以选择问题类型。</p>
<h2 id="可以自己出题，还可以邀请队友"><a href="#可以自己出题，还可以邀请队友" class="headerlink" title="可以自己出题，还可以邀请队友"></a>可以自己出题，还可以邀请队友</h2><p><a href="www.codewars.com/r/UsAiUQ">www.codewars.com/r/UsAiUQ</a><br><a href="www.codewars.com/r/UsAiUQ">codewars</a> 点一下，就可以成为我的盟友。</p>
<p><img src="https://i.imgur.com/MGFfIiV.jpg" alt=""></p>
<p>点一下，玩一年，装逼不花一分钱！</p>
<h2 id="可以上榜"><a href="#可以上榜" class="headerlink" title="可以上榜"></a>可以上榜</h2><p><a href="https://www.codewars.com/users/leaderboard" target="_blank" rel="external">leaderboard</a></p>
<p><img src="https://i.imgur.com/BsP8kJP.png" alt=""></p>
<p>第二名竟然是国人唉，不知是哪位大佬。希望有更多中国人可以出现在上面。</p>
<h1 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h1><p>目前我也还是一个萌新，希望大佬能带带我。</p>
<p>我在Github上开了一个仓库，<a href="https://github.com/zhangslob/codewars_python" target="_blank" rel="external">codewars_python</a> 里面都是用 python的解题方法，但是现在还只有几题而已，希望大家可以一起来参与，多提pr。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ATM machines allow 4 or 6 digit PIN codes and PIN codes cannot contain anything but exactly 4 digits or exactly 6 digits.</span></div><div class="line"></div><div class="line"><span class="comment"># If the function is passed a valid PIN string, return true, else return false.</span></div><div class="line"></div><div class="line"><span class="comment"># eg:</span></div><div class="line"></div><div class="line"><span class="comment"># validate_pin("1234") == True</span></div><div class="line"><span class="comment"># validate_pin("12345") == False</span></div><div class="line"><span class="comment"># validate_pin("a234") == False</span></div><div class="line"></div><div class="line"><span class="comment"># My Solutiuon</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate_pin</span><span class="params">(pin)</span>:</span></div><div class="line">    <span class="comment">#return true or false</span></div><div class="line">    <span class="keyword">return</span> pin.isdigit() <span class="keyword">if</span> len(pin) == <span class="number">4</span> <span class="keyword">or</span> len(pin) == <span class="number">6</span> <span class="keyword">else</span> <span class="keyword">False</span></div><div class="line"></div><div class="line"> <span class="comment"># Wonderful Solutiuon</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">validate_pin</span><span class="params">(pin)</span>:</span></div><div class="line">    <span class="keyword">return</span> len(pin) <span class="keyword">in</span> (<span class="number">4</span>, <span class="number">6</span>) <span class="keyword">and</span> pin.isdigit()</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;并肩作战  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/tyYtQ02.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://zhangslob.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="https://zhangslob.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="codewars" scheme="https://zhangslob.github.io/tags/codewars/"/>
    
  </entry>
  
</feed>
